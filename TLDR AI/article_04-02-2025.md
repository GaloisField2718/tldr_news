# Articles TLDR AI 04-02-2025

OpenAI has introduced "Deep Research," a research agent within ChatGPT
capable of performing multi-step research by synthesizing vast online
sources ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌  ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ 


 Sign Up [1] |Advertise [2]|View Online [3] 

		TLDR

		TOGETHER WITH [Wiz] [4]

TLDR AI 2025-02-04

 START HERE: 5 TIPS TO FIGHT AI SECURITY RISK (SPONSOR) [4] 

 Don't let AI risks catch you off guard.

Most AI security risks fall into 4 primary categories - Adversarial
attacks, model inversion attacks, data poisoning, and model theft.

Given these risks in AI systems, what's the best way to secure them? 

Wiz recently put together an eBook, _GETTING STARTED WITH AI SECURITY_
[4], to answer that exact question across the following areas:

 	* AI risks and best practices for mitigation
 	* Safeguarding your AI development pipeline
 	* Using AI to power security

Discover the 5 best strategies to secure them in this essential
guide.  

GET THE EBOOK [4]

🚀 

HEADLINES & LAUNCHES

 OPENAI'S DEEP RESEARCH (4 MINUTE READ) [5] 

 OpenAI has introduced "Deep Research," an autonomous research agent
within ChatGPT capable of performing multi-step research by
synthesizing vast online sources. It is powered by an optimized
version of the upcoming OpenAI o3 model. 

 CONSTITUTIONAL CLASSIFIERS: DEFENDING AGAINST UNIVERSAL JAILBREAKS (8
MINUTE READ) [6] 

 A new paper from the Anthropic Safeguards Research Team describes a
method that defends AI models against universal jailbreaks. A
prototype version of the method was robust to thousands of hours of
human red teaming for universal jailbreaks, albeit with high
over-refusal rates and compute overhead. An updated version achieved
similar robustness on synthetic evaluations and did so with a 0.38%
increase in refusal rates and moderate additional compute costs. 

 WHY EVERYONE IS FREAKING OUT ABOUT DEEPSEEK (13 MINUTE READ) [7] 

 DeepSeek's AI models, which are significantly cheaper to train
compared to other leading models, have disrupted the AI market,
potentially challenging Nvidia and other tech giants by showcasing
efficient use of resources. This has shaken investor confidence in the
AI sector, which traditionally believed that more spending equated to
better performance. DeepSeek's success suggests that innovation,
rather than just financial investment, could redefine the competitive
landscape. 

🧠 

RESEARCH & INNOVATION

 S1: SIMPLE TEST-TIME SCALING (45 MINUTE READ) [8] 

 A great and thorough paper that explores how to encourage models to
use more thinking tokens. One of the main findings is that with an
extremely high-quality curated dataset of 1k examples and by appending
“wait” to the end of a thinking sequence, you can encourage models
to think longer, which leads to substantially improved performance on
math and reasoning tasks. 

 DIFFUSION AUTOENCODERS ARE SCALABLE IMAGE TOKENIZERS (12 MINUTE READ)
[9] 

 The modern workhorse of multimodal understanding and generation is
learned Tokenizers. These models are typically autoencoder style with
a learned discrete codebook. They tend to work well but are very hard
to train and require careful tuning of many auxiliary losses. This
work shows that with a single diffusion loss, image tokenization is
stable, scalable, and higher quality than many traditional methods. 

 DEEPMIND'S DECODING-BASED REGRESSION IN LANGUAGE MODELS (22 MINUTE
READ) [10] 

 DeepMind researchers analyzed how language models can perform
regression tasks by decoding numeric predictions as text and found
them as effective as traditional regression models while also enabling
flexible density estimation. 

🧑‍💻 

ENGINEERING & RESOURCES

 KRON OPTIMIZER (GITHUB REPO) [11] 

 Kron is a new optimizer that is making the rounds as a strong
alternative to second-order methods. It dramatically outperforms Adam
on a number of baselines. This code is a drop-in optimizer for
PyTorch. 

 EVERYTHING YOU NEED TO BUILD STATE-OF-THE-ART FOUNDATION MODELS
(GITHUB REPO) [12] 

 Oumi is a fully open-source platform that streamlines the entire
lifecycle of foundation models, from data preparation and training to
evaluation and deployment. Whether you're developing on a laptop,
launching large-scale experiments on a cluster, or deploying models in
production, Oumi provides the tools and workflows you need. 

 GAUSSIAN SPLATTING FOR 3D RENDERING (GITHUB REPO) [13] 

 RaySplats enhances 3D Gaussian Splatting by integrating ray tracing,
improving the handling of light and shadows in 3D object rendering
while maintaining fast training and rendering speeds. 

🎁 

MISCELLANEOUS

 RLHF BOOK - POLICY GRADIENTS (45 MINUTE READ) [14] 

 Great chapter on many policy gradient methods like PPO and GRPO,
which can be used for tuning generative auto-regressive models. 

 OPENAI'S NEW ANTI-JOBS PROGRAM (7 MINUTE READ) [15] 

 OpenAI plans a $500 billion investment in "Stargate," a project aimed
at creating AI infrastructure, while economists debate the
job-creation claim as automation may perform most computer-based
tasks. DeepSeek has made significant advances with self-improving
reinforcement learning, potentially leading to rapid AI capability
improvements. This underscores China's quick progress in AI,
highlighting geopolitical stakes in the technology race. 

 AI HATERS BUILD TARPITS TO TRAP AND TRICK AI SCRAPERS THAT IGNORE
ROBOTS.TXT (12 MINUTE READ) [16] 

 Nepenthes is a tarpit malware designed to trap and poison AI web
crawlers that ignore robots.txt rules. The release of Nepenthes has
inspired other tools like Iocaine that aim to hinder AI data
collection and impact the industry financially. 

⚡ 

QUICK LINKS

 CHINESE AI FIRM DEEPSEEK HAS 50,000 NVIDIA H100 AI GPUS SAYS CEO,
EVEN WITH US RESTRICTIONS (3 MINUTE READ) [17] 

 DeepSeek, a Chinese AI lab, leveraged tens of thousands of NVIDIA
H100 GPUs to develop its R1 model, which competes with top AI models
like OpenAI's o1 and Meta's Llama. 

 DAVID SACKS CLAIMS THERE'S 'SUBSTANTIAL EVIDENCE' THAT DEEPSEEK USED
OPENAI'S MODELS TO TRAIN ITS OWN (1 MINUTE READ) [18] 

 David Sacks accused Chinese AI firm DeepSeek of using OpenAI's models
to train its own, likening the act to theft. 

 JACK DORSEY'S BLOCK HAS AN AI AGENT TOO (2 MINUTE READ) [19] 

 Jack Dorsey's Block has developed an open-source AI agent named
"codename goose" for automating engineering tasks using popular LLMs. 

Love TLDR? Tell your friends and get rewards!

 Share your referral link below with friends to get free TLDR swag! 

 https://refer.tldr.tech/34c90d5b/2 [20] 

		Track your referrals here. [21]

Want to advertise in TLDR? 📰

 If your company is interested in reaching an audience of AI
professionals and decision makers, you may want to ADVERTISE WITH US
[22]. 

Want to work at TLDR? 💼

 APPLY HERE [23] or send a friend's resume to jobs@tldr.tech and get
$1k if we hire them! 

 If you have any comments or feedback, just respond to this email! 

Thanks for reading, 
Andrew Tan [24] & Andrew Carr [25] 

 Manage your subscriptions [26] to our other newsletters on tech,
startups, and programming. Or if TLDR AI isn't for you, please
unsubscribe [27]. 

 

Links:
------
[1] https://tldr.tech/ai?utm_source=tldrai
[2] https://advertise.tldr.tech/?utm_source=tldrai&utm_medium=newsletter&utm_campaign=advertisetopnav
[3] https://a.tldrnewsletter.com/web-version?ep=1&lc=041b8714-96a1-11ed-9899-3729ef006681&p=e31e7b50-e2db-11ef-9250-b5222e15ba25&pt=campaign&t=1738678119&s=f15bc6a457ad46dc48a3627e5773d8fb33782dbd4052aeb6f3b312d9ae0116e3
[4] https://www.wiz.io/lp/getting-started-with-ai-security-ai-risks-how-to-prevent-them-and-ai-for-defender?utm_source=tldr-ai&utm_medium=paid-email&utm_campaign=FY25Q3_INB_FORM_Getting-Started-with-AI-Security-AI-Risks-How-to-Prevent-Them&sfcid=701Py00000DP3ZaIAL&utm_term=FY26Q1-tldr-ai-nl&utm_content=AISecurityeBook
[5] https://links.tldrnewsletter.com/KRFumA
[6] https://www.anthropic.com/research/constitutional-classifiers?utm_source=tldrai
[7] https://www.theverge.com/ai-artificial-intelligence/598846/deepseek-big-tech-ai-industry-nvidia-impac?utm_source=tldrai
[8] https://arxiv.org/abs/2501.19393?utm_source=tldrai
[9] https://yinboc.github.io/dito/?utm_source=tldrai
[10] https://arxiv.org/abs/2501.19383v1?utm_source=tldrai
[11] https://github.com/evanatyourservice/kron_torch?utm_source=tldrai
[12] https://github.com/oumi-ai/oumi?utm_source=tldrai
[13] https://github.com/kbyrski/raysplatting?utm_source=tldrai
[14] https://rlhfbook.com/c/11-policy-gradients.html?utm_source=tldrai
[15] https://www.vox.com/future-perfect/396548/openai-trump-artificial-intelligence-elon-musk-sam-altman-china?utm_source=tldrai
[16] https://arstechnica.com/tech-policy/2025/01/ai-haters-build-tarpits-to-trap-and-trick-ai-scrapers-that-ignore-robots-txt/?utm_source=tldrai
[17] https://www.tweaktown.com/news/102798/chinese-ai-firm-deepseek-has-50-000-nvidia-h100-gpus-says-ceo-even-with-us-restrictions/index.html?utm_source=tldrai
[18] https://techcrunch.com/2025/01/28/david-sacks-claims-theres-substantial-evidence-that-deepseek-used-openais-models-to-train-its-own/?utm_source=tldrai
[19] https://www.engadget.com/ai/jack-dorseys-block-has-an-ai-agent-too-212706083.html?utm_source=tldrai
[20] https://refer.tldr.tech/34c90d5b/2
[21] https://hub.sparklp.co/sub_46c6316534f5/2
[22] https://advertise.tldr.tech/?utm_source=tldrai&utm_medium=newsletter&utm_campaign=advertisecta
[23] https://jobs.ashbyhq.com/tldr.tech
[24] https://twitter.com/andrewztan
[25] https://twitter.com/andrew_n_carr
[26] https://tldr.tech/ai/manage?email=blockchaincryptologue%40gmail.com
[27] https://a.tldrnewsletter.com/unsubscribe?ep=1&l=eedf6b14-3de3-11ed-9a32-0241b9615763&lc=041b8714-96a1-11ed-9899-3729ef006681&p=e31e7b50-e2db-11ef-9250-b5222e15ba25&pt=campaign&pv=4&spa=1738677695&t=1738678119&s=a865add7570aec47051a9688c9b87cf5d4e02cc100f2cd4e1b58ce0e5e4a53b0