# Articles TLDR AI 16-05-2023

Together compute is, among other things, building a cloud platform for
efficient machine learning.¬† 

Sign Up [https://tldr.tech/ai?utm_source=tldr]|Jobs
[https://danni763618.typeform.com/to/rSL4lOH3]|Advertise
[https://share.hsforms.com/1OxvmrkcFS4qsxKpNXCi76wee466?utm_source=tldrai&utm_medium=newsletter]|View
Online
[https://actions.tldrnewsletter.com/web-version?ep=1&lc=041b8714-96a1-11ed-9899-3729ef006681&p=3b8309a6-f3c2-11ed-9df9-e30477d8bf6e&pt=campaign&t=1684242756&s=dd5666f8563098d5148a3b4dbd037da987e3001d2d8acde41c2d0b7be6dcb012]


		TLDR 

		TOGETHER WITH [Pieces]
[https://discover.pieces.app/lora-ml-many-lakes-vs-moat/?utm_source=tldr&utm_medium=email&utm_campaign=tldr_ai_promotion]

TLDR AI 2023-05-16

PIECES‚Äô ML: WE HAVE NO MOAT, BUT WE HAVE 1,000 LAKES (SPONSOR)
[https://discover.pieces.app/lora-ml-many-lakes-vs-moat/?utm_source=tldr&utm_medium=email&utm_campaign=tldr_ai_promotion]


Pieces has created a new solution to overcome AI training complexities
utilizing low-rank adaption (LoRA) and AI-generated labels.
Pieces leverages small, local models throughout their productivity
suite, enabling users to store, enrich, and enhance code snippets
[https://discover.pieces.app/lora-ml-many-lakes-vs-moat/?utm_source=tldr&utm_medium=email&utm_campaign=tldr_ai_promotion]
throughout their workflow.

Capture code from screenshots, generate code from natural language,
and magically enrich your materials

Enhance code readability and performance
[https://discover.pieces.app/lora-ml-many-lakes-vs-moat/?utm_source=tldr&utm_medium=email&utm_campaign=tldr_ai_promotion],
convert to boilerplate, and translate between languages or frameworks

Search, share, and reuse snippets with ease

Ready to experience the next milestone in model generation? Explore
our advanced ML features
[https://discover.pieces.app/lora-ml-many-lakes-vs-moat/?utm_source=tldr&utm_medium=email&utm_campaign=tldr_ai_promotion]
and make your workflow smarter with Pieces today.¬†

üöÄ 

HEADLINES & LAUNCHES

TOGETHER COMPUTE $20M SEED ROUND (2 MINUTE READ)
[https://www.together.xyz/blog/seed-funding?utm_source=tldrai] 

Together compute is, among other things, building a cloud platform for
efficient machine learning. With strong academic connections, and
highly talented technologists, they have a good shot of building
really useful tools for the ecosystem. One of their notable works to
date is the release of the red pajama data set, which is an open
replication of the closed data set used to train Llama. 

OPENAI‚ÄôS MOAT IS STRONGER THAN YOU THINK (5 MINUTE READ)
[https://www.airplane.dev/blog/openais-moat-is-stronger-than-you-think?utm_source=tldrai]


Despite a recent internal Google memo suggesting neither Google nor
OpenAI will be able to build a sustainable business model around large
AI models, there's an argument to the contrary. Quality AI models like
GPT-4, while seemingly easy to create, are complex and difficult to
build, and OpenAI's unique approach, including reinforcement learning
from human feedback and data filtering, offers a significant
advantage. Additionally, OpenAI's 'last-mile' delivery through ChatGPT
and the OpenAI API, along with its strong brand, make the company's
offerings tough to beat. These factors, together with OpenAI's quick
achievement of product-market fit in both B2B and B2C sectors, suggest
the company's position in the AI market is more defensible than the
memo implies. 

üß† 

RESEARCH & INNOVATION

MEGABYTE - MILLION BYTE SEQUENCES (28 MINUTE READ)
[https://arxiv.org/abs/2305.07185?utm_source=tldrai] 

Transformers are not actually end to end. There is a separate training
process for the tokenizer which is strange and often leads to odd
performance in general. However, if we try to naively train on bytes
we quickly run out of context length given the increased length of
sequences. Additionally for truly multimodal problems training
directly on bytes removes complex patching and tokenization schemes.
This work allows models to train directly on bytes with sequence
lengths up to a million bytes. Maybe this will even help nucleus
sampling for rare words too! 

STEERING LANGUAGE MODELS WITH ACTIVATIONS (32 MINUTE READ)
[https://www.alignmentforum.org/posts/5spBue2z2tw4JuDCx/steering-gpt-2-xl-by-adding-an-activation-vector?utm_source=tldrai]


One of the goals of AI safety is called scalable oversight, where we
hope to discover ways to steer language model generations without
expensive human intervention. All the ideas in this paper aren't new,
harkening back to soft prompts, it is an interesting extension. They
find that by adding activation vectors for simple ideas, they can
steer the generation towards those ideas. For example making text
happier or more prone to conspiracy theory generation. 

VIDEO QUESTION ANSWERING (45 MINUTE READ)
[https://arxiv.org/abs/2305.06988?utm_source=tldrai] 

Visual question answering has seen massive adoption over the past
several months, and rapid progress. Largely enabled by pre-trained
models such as Blip and clip. Applying these models to video is
challenging due to the dramatically increased computational
requirements. This work introduces a cascade of different models that
dramatically improves the robustness of these systems by operating at
different timescales. They use Blip2 and find strong performance. 

üßë‚Äçüíª 

ENGINEERING & RESOURCES

MICROSOFT GUIDANCE (GITHUB REPO)
[https://github.com/microsoft/guidance/?utm_source=tldrai] 

Programs are how we talk to computers, prompts are how we talk to AI,
and AI is now talking to computers. This means that we need a better
way to talk with AI. Guidance is essentially a prompting language and
toolkit developed by Microsoft that allows you to set guidelines and
instructions in a way that encourages reproducible and robust prompts.


ENHANCING 3D SCENE RECONSTRUCTION AND REALISM FROM LASER DATA (5
MINUTE READ)
[https://research.nvidia.com/labs/toronto-ai/nfl/?utm_source=tldrai] 

NFL is a new method that takes LiDAR data (a way of measuring
distances using lasers) and creates realistic 3D scenes from new
viewpoints. This technique works better than others and can help
improve tasks like mapping and understanding the environment around
us. 

EFFICIENTVIT: MEMORY EFFICIENT VISION TRANSFORMER WITH CASCADED GROUP
ATTENTION (GITHUB REPO)
[https://github.com/microsoft/Cream/tree/main/EfficientViT?utm_source=tldrai]


Researchers have created a new type of high-speed vision transformer
called EfficientViT, which combines fast processing with improved
accuracy. By redesigning certain parts of the transformer model, they
were able to significantly reduce the computational costs associated
with reshaping data and performing element-wise functions. The
experiments showed that EfficientViT outperformed other efficient
models, achieving higher accuracy while maintaining impressive
processing speeds, even surpassing MobileNetV3. 

üéÅ 

MISCELLANEOUS

UNVEILING IMAGEBIND (7 MINUTE READ)
[https://medium.com/@ignacio.de.gregorio.noblejas/imagebind-c63e4967d67c?utm_source=tldrai]


This Medium post provides an in-depth analysis of Meta's AI model,
ImageBind. ImageBind, a multi-modal AI model, can generate images from
a text description and vice versa. It is trained on a diverse range of
internet text and images. While ImageBind's accuracy and versatility
are praised, the post also acknowledges that the model can
occasionally produce irrelevant or inaccurate results. 

UNCENSORED MODELS (10 MINUTE READ)
[https://erichartford.com/uncensored-models?utm_source=tldrai] 

Eric Hartford's blog post explores the implications of uncensored AI
models, suggesting that AI censorship might be leading us down a risky
path. He argues for the development of systems to better manage the
outputs rather than suppressing them. He mentions that more research
and dialogue are needed around the ethics of AI use, and proposes the
idea of a multi-stakeholder governance model for AI systems. 

GOOGLE PLANS TO FIGHT BACK AGAINST DEEPFAKES (3 MINUTE READ)
[https://arstechnica.com/information-technology/2023/05/as-ai-generated-fakes-proliferate-google-plans-to-fight-back/?utm_source=tldrai]


Arstechnica reports that Google is preparing to combat the increasing
prevalence of AI-generated fakes. As deep fakes and other forms of
manipulated content become more sophisticated, the tech giant is
developing new tools to identify and flag this content. It plans to
implement these measures across its various platforms to ensure the
authenticity of content and protect users from misinformation.
Google's approach will involve both technology, such as AI algorithms,
and user education. 

‚ö° 

QUICK LINKS

AMAZON PLANS TO ADD CHATGPT SEARCH (2 MINUTE READ)
[https://archive.ph/jOmqk?utm_source=tldrai] 

Amazon.com Inc. plans to bring ChatGPT-style product search to its web
store, rivaling efforts by Microsoft Corp. and Google to weave
generative artificial intelligence into their search engines. 

GPT4TOOLS (GITHUB REPO)
[https://github.com/StevenGrove/GPT4Tools?utm_source=tldrai] 

GPT4Tools is a centralized system that can control multiple visual
foundation models. 

MEET THE OPENAI ‚ÄòRED TEAM‚Äô (4 MINUTE READ)
[https://archive.ph/xu0wS?utm_source=tldrai] 

OpenAI used an eclectic mix of people, known as the ‚ÄòRed Team‚Äô, to
‚Äòadversarially test‚Äô GPT-4. 

DATABERRY.AI (PRODUCT LAUNCH)
[https://www.producthunt.com/posts/databerry-ai?utm_source=tldrai] 

Databerry.ai helps you build ChatGPT Plugins to connect custom data to
ChatGPT. Talk to your data, leverage the Plugin Store to captivate
users and skyrocket your brand awareness, and get insights and
statistics on how users are interacting with your Plugin. 

TLDR TALENT [https://danni763618.typeform.com/to/rSL4lOH3] is our
exclusive community where we help world-class tech talent and get
intros to companies of their choice, along with a number of exciting
startups and tech companies curated by TLDR.

We give you full control of the process, you can specify if you‚Äôre
actively searching or passively interested only if something amazing
comes along. Set your preferred compensation, seniority/title/role,
specific companies (or types of companies) you‚Äôd like to work for
and more. CLICK HERE TO APPLY
[https://danni763618.typeform.com/to/rSL4lOH3].

If your company is interested in reaching an audience of AI
professionals and early adopters, you may want to ADVERTISE WITH US
[https://share.hsforms.com/1OxvmrkcFS4qsxKpNXCi76wee466?utm_source=tldrai&utm_medium=newsletter].


If you have any comments or feedback, just respond to this email! 

Thanks for reading, 
Andrew Tan [https://twitter.com/andrewztan] & Andrew Carr
[https://twitter.com/andrew_n_carr] 

If you don't want to receive future editions of TLDR AI, please¬†click
here to unsubscribe
[https://actions.tldrnewsletter.com/unsubscribe?ep=1&l=eedf6b14-3de3-11ed-9a32-0241b9615763&lc=041b8714-96a1-11ed-9899-3729ef006681&p=3b8309a6-f3c2-11ed-9df9-e30477d8bf6e&pt=campaign&pv=4&spa=1684242030&t=1684242756&s=9e40757e9b3daaab866bb7615d2590ec1ae1a9526388de3c0be876c035876d5a].


¬†