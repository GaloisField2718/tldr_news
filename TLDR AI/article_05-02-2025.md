# Articles TLDR AI 05-02-2025

Sundar Pichai has downplayed the efficiency of DeepSeekâ€™s AI models,
arguing that Googleâ€™s Gemini models outperform
themÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ Â â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ 


 Sign Up [1] |Advertise [2]|View Online [3] 

		TLDR 

TLDR AI 2025-02-05

ğŸš€ 

HEADLINES & LAUNCHES

 HUGGING FACE REPLICATING OPENAI'S DEEP RESEARCH (9 MINUTE READ) [4] 

 Hugging Face attempted to replicate OpenAI's Deep Research, an
agentic web-search framework that significantly improved performance
on the GAIA benchmark, by running a 24-hour-long experiment aimed at
open-sourcing an equivalent system. 

 GOOGLE CEO ON DEEPSEEK VS. GEMINI (4 MINUTE READ) [5] 

 Sundar Pichai has downplayed the efficiency of DeepSeek's AI models,
arguing that Google's Gemini models, particularly Gemini 2.0 Flash,
outperform them despite DeepSeek's disruptive impact on the AI market.


 US COPYRIGHT OFFICE RULES OUT COPYRIGHT FOR AI CREATED CONTENT
WITHOUT HUMAN INPUT (3 MINUTE READ) [6] 

 The US Copyright Office states that AI-generated works without human
intervention cannot be copyrighted. AI tools assisting with
creativity, like de-aging actors, won't limit copyright protection,
but purely generative AI outputs require further analysis. 

ğŸ§  

RESEARCH & INNOVATION

 HARMONIC LOSS TRAINS INTERPRETABLE AI MODELS (18 MINUTE READ) [7] 

 Harmonic loss is an alternative to cross-entropy loss for training
neural networks that offers better interpretability and faster
convergence through scale invariance and finite convergence points.
Experiments across algorithmic, vision, and language datasets,
demonstrate that models trained with harmonic loss show superior
performance in interpretability, data efficiency, and reduced grokking
compared to standard models. Harmonic loss could be particularly
valuable for applications with limited data or where interpretability
is crucial. 

 CONVEX OPTIMIZATION THEORY AND LEARNING-RATE SCHEDULING FOR LARGE
MODEL TRAINING (28 MINUTE READ) [8] 

 Learning-rate schedules for large models closely match theoretical
bounds from non-smooth convex optimization. These authors provide a
bound for constant schedules with linear cooldown, showing cooldown's
practical benefits through the absence of logarithmic terms in the
bound. Their findings enabled practical improvements in training
Llama-type models through optimal learning-rate extension and
cross-schedule transfer. 

 IN-CONTEXT REINFORCEMENT LEARNING (14 MINUTE READ) [9] 

 This study explores scaling In-Context Reinforcement Learning (ICRL)
to broader domains using Algorithm Distillation and shows that ICRL
can be a viable alternative to expert distillation for generalist
decision-making systems. 

ğŸ§‘â€ğŸ’» 

ENGINEERING & RESOURCES

 FORRESTER PREDICTS 75% OF DIY AI FAILS IN 2025 (SPONSOR) [10] 

 The explosive adoption of AI in 2024 has left many businesses with
spiraling costs and questionable ROI. The way forward? Ditching
cobbled-together deployments for enterprise AI platforms [10] â€”
which provides choice and control over AI solutions with complete
sovereignty from an integrated, extensible platform. Read the
Forrester report [10] 

 GOT OCR 2.0 WEIGHTS (HUGGING FACE HUB) [11] 

 One of the best OCR models is now available and integrated with the
Hugging Face ecosystem. It works well on documents and sheet music. 

 OPEN-VOCABULARY DETECTION WITH LLMS (GITHUB REPO) [12] 

 LLMDet is an open-vocabulary detector that leverages a large language
model for enhanced caption generation and grounding that significantly
boosts performance compared to existing detectors. 

 EFFICIENT CHAIN-OF-THOUGHT REASONING (16 MINUTE READ) [13] 

 Heima introduces a framework for more efficient multimodal reasoning
by compressing Chain-of-Thought processes into a single hidden token. 

ğŸ 

MISCELLANEOUS

 HOW TO SCALE YOUR MODEL (18 MINUTE READ) [14] 

 Amazing post from the DeepMind team about the mental process they use
to scale their model. They break it down into mathematical equations,
which allows them to reason about the costs of each operation and
ensure correctness. 

 WHO IS LIANG WENFENG? DEEPSEEK FOUNDER COMES FROM AI INVESTING (1
MINUTE READ) [15] 

 DeepSeek's R1 reasoning model uses less computing power than its U.S.
counterparts and is open source. The DeepSeek app topped App Store
charts over ChatGPT. Founder Liang Wenfeng previously started AI firms
and his hedge fund High-Flyer manages $8 billion, backing DeepSeek.
Liang sets himself apart by offering the product for free and open
source. 

 AI AND THE FUTURE OF NATIONAL SECURITY (8 MINUTE READ) [16] 

 Google highlights the strategic importance of AI and quantum
computing for national security, emphasizing the need for
private-sector leadership, government procurement reforms, and
public-private collaboration to strengthen cybersecurity. 

âš¡ 

QUICK LINKS

 GOOGLE'S 2024 RESPONSIBLE AI REPORT (6 MINUTE READ) [17] 

 Google has released its 6th annual Responsible AI Progress Report,
which details governance structures, safety evaluations, and risk
mitigation techniques for AI product development. 

 HUGGING FACE RESEARCHERS ARE TRYING TO BUILD A MORE OPEN VERSION OF
DEEPSEEK'S AI 'REASONING' MODEL (5 MINUTE READ) [18] 

 Hugging Face is working to replicate DeepSeek's R1 model with an
open-source initiative called Open-R1, addressing concerns over the
lack of transparency in DeepSeek's release. 

 META AI CAN NOW USE YOUR FACEBOOK AND INSTAGRAM DATA TO PERSONALIZE
ITS RESPONSES (2 MINUTE READ) [19] 

 Meta is enhancing its AI chatbot with memory capabilities that will
allow it to remember user details in conversations on Facebook,
Messenger, and WhatsApp in the U.S. 

Love TLDR? Tell your friends and get rewards!

 Share your referral link below with friends to get free TLDR swag! 

 https://refer.tldr.tech/34c90d5b/2 [20] 

		 Track your referrals here. [21] 

Want to advertise in TLDR? ğŸ“°

 If your company is interested in reaching an audience of AI
professionals and decision makers, you may want to ADVERTISE WITH US
[22]. 

Want to work at TLDR? ğŸ’¼

 APPLY HERE [23] or send a friend's resume to jobs@tldr.tech and get
$1k if we hire them! 

 If you have any comments or feedback, just respond to this email! 

Thanks for reading, 
Andrew Tan [24] & Andrew Carr [25] 

 Manage your subscriptions [26] to our other newsletters on tech,
startups, and programming. Or if TLDR AI isn't for you, please
unsubscribe [27]. 

 

Links:
------
[1] https://tldr.tech/ai?utm_source=tldrai
[2] https://advertise.tldr.tech/?utm_source=tldrai&utm_medium=newsletter&utm_campaign=advertisetopnav
[3] https://a.tldrnewsletter.com/web-version?ep=1&lc=041b8714-96a1-11ed-9899-3729ef006681&p=ae10036e-e3a5-11ef-afb3-059c5ab58181&pt=campaign&t=1738764479&s=17aaa43b55065175e30777f131e3b935b4248e23acb6448ab97ddceb4e47cb2d
[4] https://huggingface.co/blog/open-deep-research?utm_source=tldrai
[5] https://www.crn.com/news/ai/2025/google-q4-2024-earnings-ceo-pichai-says-deepseek-models-less-efficient-than-gemini-s?utm_source=tldrai
[6] https://www.techspot.com/news/106562-us-copyright-office-rules-out-copyright-ai-created.html?utm_source=tldrai
[7] https://arxiv.org/abs/2502.01628?utm_source=tldrai
[8] https://arxiv.org/abs/2501.18965?utm_source=tldrai
[9] https://arxiv.org/abs/2501.19400v1?utm_source=tldrai
[10] https://more.suse.com/Forrester_Artificial_Intelligence_Predictions.html?utm_source=&utm_medium=&utm_campaign=2_0007061_Forrester_Artificial_Intelligence_Predictions_for_2025_us_2025153_en&utm_term=TLDR
[11] https://huggingface.co/stepfun-ai/GOT-OCR-2.0-hf?utm_source=tldrai
[12] https://github.com/isee-laboratory/llmdet?utm_source=tldrai
[13] https://arxiv.org/abs/2501.19201v1?utm_source=tldrai
[14] https://jax-ml.github.io/scaling-book/?utm_source=tldrai
[15] https://techcrunch.com/2025/01/28/who-is-liang-wenfeng-deepseek-founder-comes-from-ai-investing/?utm_source=tldrai
[16] https://blog.google/technology/safety-security/ai-and-the-future-of-national-security/?utm_source=tldrai
[17] https://blog.google/technology/ai/responsible-ai-2024-report-ongoing-work/?utm_source=tldrai
[18] https://techcrunch.com/2025/01/28/hugging-face-researchers-are-trying-to-build-a-more-open-version-of-deepseeks-ai-reasoning-model/?utm_source=tldrai
[19] https://techcrunch.com/2025/01/27/meta-ai-can-now-use-your-facebook-and-instagram-data-to-personalize-its-responses/?utm_source=tldrai
[20] https://refer.tldr.tech/34c90d5b/2
[21] https://hub.sparklp.co/sub_46c6316534f5/2
[22] https://advertise.tldr.tech/?utm_source=tldrai&utm_medium=newsletter&utm_campaign=advertisecta
[23] https://jobs.ashbyhq.com/tldr.tech
[24] https://twitter.com/andrewztan
[25] https://twitter.com/andrew_n_carr
[26] https://tldr.tech/ai/manage?email=blockchaincryptologue%40gmail.com
[27] https://a.tldrnewsletter.com/unsubscribe?ep=1&l=eedf6b14-3de3-11ed-9a32-0241b9615763&lc=041b8714-96a1-11ed-9899-3729ef006681&p=ae10036e-e3a5-11ef-afb3-059c5ab58181&pt=campaign&pv=4&spa=1738764059&t=1738764479&s=936744b993e04eaf0f994e92e13825b4659f060afef9ac63c712f61b24a1cc84