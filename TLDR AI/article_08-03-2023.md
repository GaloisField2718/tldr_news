# Articles TLDR AI 08-03-2023

Initially investing in Cohere, Anthropic, You.com, and HealthAI this
new fund will focus on accelerating generative AI companies across the
board.¬† 

Sign Up [https://tldr.tech/ai?utm_source=tldr]|Jobs
[https://tldr.tech/jobs]|Advertise
[https://danni763618.typeform.com/to/K4Gdz1?utm_source=tldrai&utm_medium=newsletter#newsletter=ai]|View
Online
[https://actions.tldrnewsletter.com/web-version?ep=1&lc=041b8714-96a1-11ed-9899-3729ef006681&p=c9ed2f38-bd7f-11ed-bac7-e7296b65141f&pt=campaign&t=1678284370&s=4d09167bf66aa7b17b09cac9a937bc9aaf359f7210c90cdce006ff364f871eae]


		TLDR 

DAILY UPDATE 2023-03-08

üöÄ 

HEADLINES & LAUNCHES

SALESFORCE $250MM GENERATIVE AI FUND (2 MINUTE READ)
[https://www.salesforce.com/news/stories/generative-ai-investing/?utm_source=tldrai]


Initially investing in Cohere, Anthropic, You.com, and HealthAI this
new fund will focus on accelerating generative AI companies across the
board. They want to work with companies that will impact a user's
daily workflow. 

STABILITY AI ACQUIRES CLIPDROP (1 MINUTE READ)
[https://stability.ai/blog/stability-ai-acquires-init-ml-makers-of-clipdrop-application?utm_source=tldrai]


Started in 2020, ClipDrop is a fantastic computer vision application
that allows you to edit images with various AI enhanced tools. They
plan to integrate future Stability models natively into ClipDrop which
already has over 15 million users. 

STATE OF COMPETITIVE ML 2022 (14 MINUTE READ)
[https://mlcontests.com/state-of-competitive-machine-learning-2022/?utm_source=tldrai]


Competitive ML is an ever growing field it is often hard to keep up,
here are some highlights from 2022. Kaggle is still the most dominant
platform for data science competitions, but there are other platforms
with decent prize money. Python is the most commonly used language and
96% of Deep Learning solutions used PyTorch - which is up from 77% the
prior year. Winners of NLP competitions used Transformers, while
computer vision solutions mainly used CNNs. Tabular data competitions
were mostly won by GBDTs, with LightGBM being the most popular. Half
of the competition winners are first-time winners. 

üß† 

RESEARCH & INNOVATION

PALM-E (4 MINUTE READ) [https://palm-e.github.io/?utm_source=tldrai] 

The term ‚Äúpositive transfer‚Äù is somewhat of a holy grail for large
scale models. It means that when you train on two modalities, you get
better performance than you would have training on just one or the
other. This paper from Google shows that training on robot controls,
video, and text shows positive transfer between domains. This is
hypothesized to be a function of model scale, and this model is an
impressive 562 billion parameters. 

PRISMER: A VISION-LANGUAGE MODEL WITH MULTI-MODAL EXPERTS (5 MINUTE
READ) [https://shikun.io/projects/prismer?utm_source=tldrai] 

The article discusses the high computational and data requirements of
large pre-trained models used in vision-language learning, which
require massive amounts of image-text data to be trained. The proposed
alternative approach involves using separate sub-networks or "experts"
for specific tasks, allowing for the use of domain-specific data and
architectures that would not be feasible with a single large network.
The proposed model, Prismer, is a visually conditioned autoregressive
text generation model that utilizes powerful vision-only and
language-only models along with modality-specific vision experts for
open-ended vision-language reasoning tasks. The expert models are
pre-trained and frozen, and connected through lightweight trainable
components, comprising only 20% of total network parameters, leading
to improved training efficiency and scalability. 

üßë‚Äçüíª 

ENGINEERING & RESOURCES

DAVINCI FUNCTIONS (GITHUB REPO)
[https://github.com/odashi/davinci-functions?utm_source=tldrai] 

There are common things you want to do with large language models such
as text-divinci-003 such as write a list, answer a question, or verify
a statement. This repo provides some simple tools for doing those
tasks. It is a cool step towards building an abstraction layer on top
of these models. 

CODE FOR THE CURRENT BEST ATTENTION-FREE LONG CONTEXT LANGUAGE MODEL
(GITHUB REPO)
[https://github.com/HazyResearch/safari/blob/main/standalone_hyena.py?utm_source=tldrai]


The SSM literature has been receiving increased attention recently
after S4 showed phenomenal performance on the long range arena
benchmark. The latest work in the series has closed the gap on
language modeling tasks with attention based Transformers while
scaling to 10x longer context 100x faster. 

NERFLETS: LOCAL RADIANCE FIELDS FOR EFFICIENT STRUCTURE-AWARE 3D SCENE
REPRESENTATION FROM 2D SUPERVISION (5 MINUTE READ)
[https://jetd1.github.io/nerflets-web/?utm_source=tldrai] 

The paper introduces "Nerflets," a local neural radiance field that
represents a 3D scene efficiently and with structure awareness.
Nerflets are composed of multiple neural radiance fields that maintain
their own spatial position, orientation, and extent to contribute to
panoptic, density, and radiance reconstructions. By using only
photometric and inferred panoptic image supervision, Nerflets allow
the extraction of panoptic and photometric renderings from arbitrary
views, and enable tasks rare for NeRFs, such as 3D panoptic
segmentation and interactive editing. The experiments show that
Nerflets fit and approximate the scene more efficiently than
traditional global NeRFs. 

WORRIED ABOUT AI STEALING YOUR JOB? STAY ONE STEP AHEAD WITH
BITE-SIZED INTERACTIVE LESSONS (SPONSOR)
[https://brilliant.org/tldrai/] 

It‚Äôs pretty clear that AI is going to eat the world. Are you ready
for it? With¬†Brilliant [https://brilliant.org/tldrai/], you
can¬†master and practice AI concepts in just 15 minutes a day
[https://brilliant.org/tldrai/]. Skill up on math, AI, neural
networks, and more through guided interactive problem solving that's
effective and fun.¬†Try Brilliant free for 30 days +¬†claim a 20%
discount for TLDR readers [https://brilliant.org/tldrai/] 

üéÅ 

MISCELLANEOUS

SGD IN SQL (13 MINUTE READ)
[https://maxhalford.github.io/blog/ogd-in-sql/?utm_source=tldrai] 

Looking to reduce MLOps complexity? Just write everything in your
database! This fun little post takes this idea to the limit and writes
gradient calculations in SQL. 

SCALE AI: WHY DATA WILL POWER THE AI REVOLUTION (8 MINUTE READ)
[https://www.indexventures.com/perspectives/scale-ai-why-data-will-power-the-ai-revolution/?utm_source=tldrai]


This article by Index Ventures covers the story of Scale AI, one of
the most successful AI startups from the last 5 years. Scale AI is the
data platform for AI, providing high quality training data for leading
machine learning teams. It was started by Alexandr Wang when he was
just 19 years old and is now valued at over $7 billion. The article
talks about how Scale got started, what made it so successful, and
where the company and AI as a whole is headed. 

CONSIDERATIONS FOR AI-NATIVE STARTUPS (7 MINUTE READ)
[https://tanay.substack.com/p/considerations-for-ai-native-startups?utm_source=tldrai]


As large language models have exploded over the past year, numerous
startups have begun to build AI-native applications to disrupt
industries. There's been a lot of talk about how many of them are
simply ‚Äúwrappers on OpenAI‚Äù as part of discussions about moats and
defensibility. This article dives into how AI-native startups should
think about moats, defensibility, and more. 

‚ö° 

QUICK LINKS

DON‚ÄôT FEAR AN AI-INDUCED JOBS APOCALYPSE JUST YET (8 MINUTE READ)
[https://archive.is/Nw3FA?utm_source=tldrai] 

This article makes the case that because the west suffers from too
little automation, not too much, it is unlikely that AI causes mass
unemployment. 

VCS SKEPTICAL OVER AI (5 MINUTE READ)
[https://www.ft.com/content/5671094e-6b09-43a2-9a11-7bc19f382793?utm_source=tldrai]


Venture capitalists have some concerns over the profitability
potential of AI, with their ultimate fear being a repeat of crypto. 

CATEGORY THEORY MACHINE LEARNING (GITHUB REPO)
[https://github.com/bgavran/Category_Theory_Machine_Learning?utm_source=tldrai]


This GitHub repo is a collection of category theory papers. 

STABLEDIFFUSION-PLUGIN (GITHUB REPO)
[https://github.com/AbdullahAlfaraj/Auto-Photoshop-StableDiffusion-Plugin?utm_source=tldrai]


StableDiffusion-Plugin allows you to directly use the capabilities of
Automatic1111 Stable Diffusion in Photoshop without switching between
programs. 

If you are in a hiring position, you may want to HIRE AI TALENT
THROUGH OUR FREE JOB BOARD [https://tldr.tech/employer/sign-up]. 

If your company is interested in reaching an audience of AI
decision-makers, researchers, and engineers, you may want to ADVERTISE
WITH US
[https://danni763618.typeform.com/to/K4Gdz1?utm_source=tldrai&utm_medium=newsletter#newsletter=ai].


If you have any comments or feedback, just respond to this email! 

Thanks for reading, 
Andrew Tan (@ANDREWZTAN [https://twitter.com/andrewztan]) & Andrew
Carr (@ANDREW_N_CARR [https://twitter.com/andrew_n_carr]) 

If you don't want to receive future editions of TLDR AI, please¬†click
here to unsubscribe
[https://actions.tldrnewsletter.com/unsubscribe?ep=1&l=eedf6b14-3de3-11ed-9a32-0241b9615763&lc=041b8714-96a1-11ed-9899-3729ef006681&p=c9ed2f38-bd7f-11ed-bac7-e7296b65141f&pt=campaign&pv=4&spa=1678284019&t=1678284370&s=54d932b471645e6e3257726cb29ea18ea3cac84a46d4601e71fda9d52f3cf030].


¬†