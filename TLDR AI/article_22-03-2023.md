# Articles TLDR AI 22-03-2023

Its here! Google‚Äôs long anticipated entry into the language models
as a service game.¬† 

Sign Up [https://tldr.tech/ai?utm_source=tldr]|Jobs
[https://tldr.tech/jobs]|Advertise
[https://share.hsforms.com/1OxvmrkcFS4qsxKpNXCi76wee466?utm_source=tldrai&utm_medium=newsletter]|View
Online
[https://actions.tldrnewsletter.com/web-version?ep=1&lc=041b8714-96a1-11ed-9899-3729ef006681&p=861f6640-c87e-11ed-bd27-61a1832806d7&pt=campaign&t=1679490426&s=6288f8467d66d897977498eb892d8e0b9975689315950e15b342d43ee759e0e7]


		TLDR 

DAILY UPDATE 2023-03-22

üöÄ 

HEADLINES & LAUNCHES

GOOGLE LAUNCHES BARD (4 MINUTE READ)
[https://blog.google/technology/ai/try-bard/?utm_source=tldrai] 

It's here! Google‚Äôs long anticipated entry into the language models
as a service game. Bard is a lightweight version of Lambda, which was
a 70B parameter conversational agent trained a few years ago. They
have spent a lot of effort making things safe and grounded in
truthfulness, we‚Äôll see when people start getting added to the
waitlist if it lives up to the promises! 

OPENAI DISCONTINUES CODEX (1 MINUTE READ)
[https://threadreaderapp.com/thread/1638011552401096705.html?utm_source=tldrai]


The set of 4 popular coding models that were in free beta since 2021
are being discontinued in favor of the turbo and gpt-4 models. While
those models are quite adept at coding, the research community is
concerned that sunsetting these models will dramatically reduce the
ability to reproduce prior research built on them. At least we know
OpenAI is truly a tech company now. 

ADOBE‚ÄôS HOME GROWN GENERATIVE MODELS (2 MINUTE READ)
[https://www.adobe.com/sensei/generative-ai/firefly.html?utm_source=tldrai]


Player 2 has entered the game. Adobe has launched a private beta for
their Firefly set of models. Backed by a strong vision team and access
to significant data the art behemoth is now poised to offer their own
generative image models. There is a growing hypothesis that tech
matters less and distribution is still king, when both are combined,
we‚Äôll see what happens! 

üß† 

RESEARCH & INNOVATION

GOOGLE PROPOSES SVDIFF, A PERSONALIZED TEXT-TO-IMAGE DIFFUSION MODEL
(11 MINUTE READ) [https://arxiv.org/abs/2303.11305?utm_source=tldrai] 

Researchers from Google propose a novel approach called SVDiff to
address the limitations of existing text-to-image diffusion models for
personalization, including overfitting and inefficient parameter
storage. SVDiff involves fine-tuning the singular values of weight
matrices, resulting in a compact and efficient parameter space that
reduces the risk of overfitting, language-drifting, and has a
significantly smaller model size, making it more practical for
real-world applications. 

ZERO-1-TO-3: ZERO-SHOT ONE IMAGE TO 3D OBJECT (9 MINUTE READ)
[https://arxiv.org/abs/2303.11328?utm_source=tldrai] 

Zero-1-to-3 is a framework for changing the camera viewpoint of an
object from a single RGB image, using a conditional diffusion model
that learns controls of relative camera viewpoint from a synthetic
dataset. This approach shows strong zero-shot generalization abilities
to out-of-distribution datasets and in-the-wild images, including
impressionist paintings, and can be used for 3D reconstruction from a
single image, outperforming state-of-the-art models by leveraging
Internet-scale pre-training. 

üßë‚Äçüíª 

ENGINEERING & RESOURCES

HOW MANY GPUS DO I NEED TO TRAIN MY MODEL? (1 MINUTE READ)
[https://github.com/mosaicml/examples/tree/main/examples/llm#how-many-gpus-do-i-need-to-train-a-llm?utm_source=tldrai]


The short is you need a minimum of 16 * N (billion params) GB of
cluster memory to train a model. Convergence speed and training time
will be helped by larger clusters, but this is a good way to reason
about costs vs performance with customly trained models. 

GPTNEOX 2.0 (GITHUB REPO)
[https://github.com/EleutherAI/gpt-neox/releases/tag/v2.0?utm_source=tldrai]


One of the best, open, model parallel training libraries available is
now up-to-date with the latest deepspeed version. Keeping the two
projects in sync has always been a challenge, and now will receive
more focus going forward. If you want to train a model with billions
of parameters from scratch, this is likely the repo for you. 

CLIP GOES 3D (GITHUB REPO)
[https://github.com/deeptibhegde/CLIP-goes-3D?utm_source=tldrai] 

CG3D proposes a framework for zero-shot 3D geometric feature
extraction by training a 3D encoder using point clouds, rendered 2D
images, and text. Contrastive loss aligns features in a multimodal
embedding space, and prompt tuning with trainable input parameters
overcomes distribution shift issues. CG3D demonstrates impressive
zero-shot, open-scene understanding, and retrieval capabilities, and
serves as a strong starting weight for downstream 3D recognition
tasks. 

üéÅ 

MISCELLANEOUS

NVIDIA H SERIES OF CHIPS GETS A MEMORY BOOST (3 MINUTE READ)
[https://www.anandtech.com/show/18780/nvidia-announces-h100-nvl-max-memory-server-card-for-large-language-models?utm_source=tldrai]


Most large language models are constrained by the on chip memory. This
new series of chips offers 188 GB of on chip memory which is
astonishing. With 990 TFLOPS as well, expect to see this card used
more often for training and inference for expensive models. 

OPPORTUNITIES IN AI X TRAVEL (5 MINUTE READ)
[https://a16z.com/2023/03/21/ai-travel-opportunities/?utm_source=tldrai]


In this article, a16z argues that the travel industry is ripe for
disruption from AI in all areas from planning a trip to booking
flights to on the trip itself. Generative AI can be used to draw
insights and suggestions from public and private data about travel
preferences, locations, transportation, and activities. Startups can
leverage AI for inspiration, itinerary planning, booking, and trip
assistance, creating more conversational and customized experiences
for travelers. 

THE CASE FOR SLOWING DOWN AI (10 MINUTE READ)
[https://www.vox.com/the-highlight/23621198/artificial-intelligence-chatgpt-openai-existential-risk-china-ai-safety-technology?utm_source=tldrai]


This article makes the case that we are moving too fast on AI, and
that perhaps slowing down to better understand the risks is the best
choice for humanity. 

‚ö° 

QUICK LINKS

BING NOW LET‚ÄôS YOU CREATE IMAGES WITH DALL-E (2 MINUTE READ)
[https://www.theverge.com/2023/3/21/23649943/microsoft-bing-openai-dall-e-image-creator-ai?utm_source=tldrai]


Microsoft‚Äôs Bing chatbot now has an AI-powered image creator built
into the search engine. 

AI COMMITS (GITHUB REPO)
[https://github.com/Nutlope/aicommits?utm_source=tldrai] 

AI Commits is a CLI that writes your git commit messages for you with
AI. 

AWESOME-TOTALLY-OPEN-CHATGPT (GITHUB REPO)
[https://github.com/nichtdax/awesome-totally-open-chatgpt?utm_source=tldrai]


This GitHub repo is a list of open-source ChatGPT alternatives. 

CANCELEDGPT (PRODUCT) [https://canceledgpt.com/?utm_source=tldrai] 

CanceledGPT is a website that uses AI to search through and revise
your old offensive tweets. 

If you are in a hiring position, you may want to HIRE AI TALENT
THROUGH OUR FREE JOB BOARD [https://tldr.tech/employer/sign-up]. 

If your company is interested in reaching an audience of AI
decision-makers, researchers, and engineers, you may want to ADVERTISE
WITH US
[https://share.hsforms.com/1OxvmrkcFS4qsxKpNXCi76wee466?utm_source=tldrai&utm_medium=newsletter].


If you have any comments or feedback, just respond to this email! 

Thanks for reading, 
Andrew Tan [https://twitter.com/andrewztan] & Andrew Carr
[https://twitter.com/andrew_n_carr] 

If you don't want to receive future editions of TLDR AI, please¬†click
here to unsubscribe
[https://actions.tldrnewsletter.com/unsubscribe?ep=1&l=eedf6b14-3de3-11ed-9a32-0241b9615763&lc=041b8714-96a1-11ed-9899-3729ef006681&p=861f6640-c87e-11ed-bd27-61a1832806d7&pt=campaign&pv=4&spa=1679490021&t=1679490426&s=1d75b46a197175f0f6821a6fb3e8415e2f019543effc07bca479f28d7efb5c33].


¬†