# Articles TLDR AI 15-09-2025

Grok 4 Fast, the newest addition to xAI's lineup, is now available for
users on the Grok web interface via the model
selectorÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ Â â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ 


 Sign Up [1] |Advertise [2]|View Online [3] 

		TLDR 

		TOGETHER WITH [Baseten] [4]

TLDR AI 2025-09-15

 BASETEN RAISES $150M SERIES D AT $2.15B VALUATION (SPONSOR) [4] 

 As the next generation of AI applications comes to market, ambitious
teams are turning to Baseten for inference infra [4] that not only
keeps up with but accelerates their innovation.

Fueled by the growth of customers like OpenEvidence, Abridge, Clay,
Sourcegraph, Hex, and Zed, Baseten has announced a $150M Series D at a
$2.15B valuation - just 6 months after a $75M Series C.Â 

This funding will help the team meet surging demand and continue
powering the fastest-growing AI companies. Try them out here [4].

ğŸš€ 

HEADLINES & LAUNCHES

 XAI LAYS OFF 500 DATA ANNOTATORS (1 MINUTE READ) [5] 

 xAI has reportedly laid off a third of its data annotation team as it
pivots to expand its specialized AI tutor division. 

 XAI LAUNCHES GROK 4 FAST IN EARLY ACCESS BETA WITH UP TO 10X SPEED (1
MINUTE READ) [6] 

 Grok 4 Fast, the newest addition to xAI's lineup, is now available
for users on the Grok web interface via the model selector. It can be
accessed by enabling a new toggle in the Subscription settings. Marked
as an early access beta, Grok 4 Fast is up to 10 times quicker than
the standard Grok 4. It is optimized to respond rapidly by spending
minimal processing time on complex tasks, which limits its creative
abilities. 

ğŸ§  

DEEP DIVES & ANALYSIS

 POST-TRAINING 101 FOR LLMS (39 MINUTE READ) [7] 

 A walkthrough of the entire post-training lifecycle of LLMs, from
supervised fine-tuning and reward modeling to reinforcement learning
methods such as RLHF, along with evaluation best practices. 

 THE VERTICAL AI PLAYBOOK (BOOK) [8] 

 Despite billions invested, 42% of enterprise AI initiatives were
discontinued in 2024. This was caused by how models were embedded into
business. The winners redesign workflows, rethink structures, and take
ownership of the service layer where value is created. The next
generation of CEOs will treat AI as a labor class and deploy the
technology with the same discipline that the most successful serial
acquirers apply to capital. 

 BREAKING GPT-OSS: A BRIEF INVESTIGATION (6 MINUTE READ) [9] 

 This article evaluates different jailbreaking methods against
gpt-oss. The model appears to have had robust safety training in both
system prompting and refusal vector attacks. It is tricky to work
with, and not all libraries support its idiosyncrasies. 

ğŸ§‘â€ğŸ’» 

ENGINEERING & RESEARCH

 GARTNER'S LATEST MAGIC QUADRANT COMPARES THE TOP CLOUD INFRASTRUCTURE
PROVIDERS (SPONSOR) [10] 

 The 2025 GartnerÂ® Magic Quadrantâ„¢ for Strategic Cloud Platform
Services [10] compares Google, Microsoft, Amazon, and 5 other leaders
in cloud infrastructure. It looks at dozens of mandatory and common
features that determine a vendor's ability to support mission-critical
workloads. Find out why Google was named a leader [10] 

 VAULTGEMMA: THE WORLD'S MOST CAPABLE DIFFERENTIALLY PRIVATE LLM (11
MINUTE READ) [11] 

 VaultGemma is a model that Google trained from scratch with
Differential Privacy (DP). DP offers a mathematically robust solution
to user privacy that adds calibrated noise to present memorization. It
has some trade-offs, like reducing training stability and
significantly increasing batch size. There is still a utility gap
between DP-trained and non-DP-trained models, but that gap can be
systematically narrowed with more research on mechanism design for DP
training. 

 THE ILLUSION OF DIMINISHING RETURNS: MEASURING LONG HORIZON EXECUTION
IN LLMS (1 MINUTE READ) [12] 

 Real-world value often stems from the length of a task an agent can
complete. Marginal gains in single-step accuracy can compound into
exponential improvements in the length of a task a model can
successfully complete. Models are more likely to make mistakes when
the context contains errors from previous turns. Failures when tasks
are made longer arise from mistakes in execution rather than an
inability to reason. 

 THE SECOND WAVE OF MCP: BUILDING FOR LLMS, NOT DEVELOPERS (3 MINUTE
READ) [13] 

 Teams that shift from API shaped tools to workflow-shaped tools see
meaningful improvements in reliability and efficiency. MCP works best
when tools handle complete user intentions rather than exposing
individual API operations. Large language models don't work like
developers - they have to constantly rediscover which tools exist, how
to use them, and in what order, so building tools around workflows
produces better results. 

ğŸ 

MISCELLANEOUS

 YOU SHOULD BE REWRITING YOUR PROMPTS (6 MINUTE READ) [14] 

 Models aren't perfectly interchangeable - if you are switching
models, rewrite your prompts. Prompts overfit to models the same way
models overfit to data. They need to be tested, evaluated, and aligned
with the defaults of the new model. Adapting prompts will save tokens
while producing better results. 

 AI WILL NOT MAKE YOU RICH (35 MINUTE READ) [15] 

 Most of the new value created by AI will be captured by consumers,
who will see wider and more affordable access to services like medical
care, education, and advice. Knowledge-intensive services will get
cheaper, allowing consumers to buy more of them. At the same time,
services that require person-to-person interaction will get more
expensive and take up a greater percentage of household spending.
There will be obvious opportunities in both. Think through the
implications of knowledge workers becoming more efficient, imagine
what markets this efficiency unlocks, and invest in those. 

âš¡ 

QUICK LINKS

 WARP ANNOUNCES WARP CODE - THE ULTIMATE AGENTIC DEVELOPMENT
ENVIRONMENT (SPONSOR) [16] 

 Warp already beat Claude Code and Cursor in agent benchmarks. Now it
has a nifty editor, code review, and other tools that make it the
perfect AI coding environment. Try Warp Code for free [16] 

 UNDERSTANDING GPU ARCHITECTURE (35 MINUTE READ) [17] 

 Cornell's Center for Advanced Computing published an interactive
workshop covering GPU memory hierarchies, streaming multiprocessors,
and detailed breakdowns of NVIDIA's Tesla V100 and Quadro RTX 5000
architectures. 

 MANAGING AGENT MEMORY WITH SESSIONS (19 MINUTE READ) [18] 

 How to manage short-term memory for AI agents using the OpenAI Agents
SDK, employing trimming and compression techniques to keep sessions
coherent, fast, and reliable. 

 NVIDIA STEPS BACK FROM DGX CLOUD â€” STOPS TRYING TO COMPETE WITH AWS
AND AZURE (2 MINUTE READ) [19] 

 Nvidia now uses its DGX Cloud capacity for internal research. 

 OPENAI GROVE PROGRAM ANNOUNCEMENT (1 MINUTE READ) [20] 

 OpenAI has announced a 5-week residency for early-stage technical
founders, offering mentorship, early tool access, and peer
collaboration to explore new AI product ideas. 

Love TLDR? Tell your friends and get rewards!

 Share your referral link below with friends to get free TLDR swag! 

 https://refer.tldr.tech/34c90d5b/2 [21] 

		 Track your referrals here. [22] 

Want to advertise in TLDR? ğŸ“°

 If your company is interested in reaching an audience of AI
professionals and decision makers, you may want to ADVERTISE WITH US
[23]. 

Want to work at TLDR? ğŸ’¼

 APPLY HERE [24] or send a friend's resume to jobs@tldr.tech and get
$1k if we hire them! 

 If you have any comments or feedback, just respond to this email! 

Thanks for reading, 
Andrew Tan [25], Ali Aminian [26], Jacob Turner [27] & Sahil Khoja
[28] 

 Manage your subscriptions [29] to our other newsletters on tech,
startups, and programming. Or if TLDR AI isn't for you, please
unsubscribe [30]. 

 

Links:
------
[1] https://tldr.tech/ai?utm_source=tldrai
[2] https://advertise.tldr.tech/?utm_source=tldrai&utm_medium=newsletter&utm_campaign=advertisetopnav
[3] https://a.tldrnewsletter.com/web-version?ep=1&lc=041b8714-96a1-11ed-9899-3729ef006681&p=3ce17f4e-9226-11f0-beb2-2dc5e863a6eb&pt=campaign&t=1757941835&s=f0bf840901687f04fe3696a52398ecea815f1c780c38f18964edff935bb9b37a
[4] https://login.baseten.co/sign-up?state=eyJuZXh0X3VybCI6bnVsbH0%3A1ux5mS%3AXsp1P0NZdqAn3f98fbZutaudZRckgVFwBjEm2104XQM&redirect_uri=https%3A%2F%2Fapp.baseten.co%2Fapi%2Fauth%2Fcallback&authorization_session_id=01K4Z8Z8YNY3PJCZMHD66ARQ88/?utm_source=affiliates&utm_medium=tldr_tech&utm_campaign=9_15_primary_tldr&utm_term=Series_D&utm_content=newsletter
[5] https://techcrunch.com/2025/09/13/xai-reportedly-lays-off-500-workers-from-data-annotation-team/?utm_source=tldrai
[6] https://www.testingcatalog.com/xai-launches-grok-4-fast-in-early-access-beta-with-up-to-10x-speed/?utm_source=tldrai
[7] https://tokens-for-thoughts.notion.site/post-training-101?utm_source=tldrai
[8] https://research.contrary.com/deep-dive/the-vertical-ai-playbook?utm_source=tldrai
[9] https://www.lesswrong.com/posts/HfXyF4swFLpeLuv3W/breaking-gpt-oss-a-brief-investigation?utm_source=tldrai
[10] https://cloud.google.com/resources/content/2025-gartner-magic-quadrant-strategic-cloud-platform-services?e=48754805&hl=en&utm_source=cloud_sfdc&utm_medium=email&utm_campaign=FY25-Q3-GLOBAL-ENT36283-website-dl-2025SCPSMQ-88982&utm_content=tldr&utm_term=september_15
[11] https://research.google/blog/vaultgemma-the-worlds-most-capable-differentially-private-llm/?utm_source=tldrai
[12] https://arxiv.org/abs/2509.09677?utm_source=tldrai
[13] https://vercel.com/blog/the-second-wave-of-mcp-building-for-llms-not-developers?utm_source=tldrai
[14] https://maxleiter.com/blog/rewrite-your-prompts?utm_source=tldrai
[15] https://joincolossus.com/article/ai-will-not-make-you-rich/?utm_source=tldrai
[16] https://www.warp.dev/code?utm_source=publications&utm_medium=newsletter&utm_campaign=warp_code_9_15_quicklinks&utm_content=tldr_ai
[17] https://cvw.cac.cornell.edu/gpu-architecture?utm_source=tldrai
[18] https://cookbook.openai.com/examples/agents_sdk/session_memory?utm_source=tldrai
[19] https://www.tomshardware.com/tech-industry/nvidia-steps-back-from-dgx-cloud?utm_source=tldrai
[20] https://links.tldrnewsletter.com/iGSIfq
[21] https://refer.tldr.tech/34c90d5b/2
[22] https://hub.sparklp.co/sub_46c6316534f5/2
[23] https://advertise.tldr.tech/?utm_source=tldrai&utm_medium=newsletter&utm_campaign=advertisecta
[24] https://jobs.ashbyhq.com/tldr.tech
[25] https://twitter.com/andrewztan
[26] https://www.linkedin.com/in/aliiaminian/
[27] https://www.linkedin.com/in/jacob-turner-7521a8198/
[28] https://www.linkedin.com/in/sahilkhoja/
[29] https://tldr.tech/ai/manage?email=blockchaincryptologue%40gmail.com
[30] https://a.tldrnewsletter.com/unsubscribe?ep=1&l=eedf6b14-3de3-11ed-9a32-0241b9615763&lc=041b8714-96a1-11ed-9899-3729ef006681&p=3ce17f4e-9226-11f0-beb2-2dc5e863a6eb&pt=campaign&pv=4&spa=1757941255&t=1757941835&s=58962b405a272ac69780823063fecbebfd890ad697daae3d634057458a6c8ed7