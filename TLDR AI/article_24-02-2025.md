# Articles TLDR AI 24-02-2025

Chinese AI lab DeepSeek plans to open source portions of its online
servicesâ€™ code as part of an â€œopen source weekâ€
event.Â â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ Â â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ 


 Sign Up [1] |Advertise [2]|View Online [3] 

		TLDR 

TLDR AI 2025-02-24

ğŸš€ 

HEADLINES & LAUNCHES

 OPENAI'S SHIFT FROM MICROSOFT TO SOFTBANK (1 MINUTE READ) [4] 

 OpenAI plans to source most of its computing power from SoftBank's
Stargate project by 2030, marking a significant departure from its
reliance on Microsoft. 

 META'S DINOV2 FOR CANCER RESEARCH (3 MINUTE READ) [5] 

 Orakl Oncology uses Meta's DINOv2 model to accelerate cancer drug
discovery, improving efficiency by quickly analyzing organoid images
to predict patient treatment responses. 

 DEEPSEEK TO OPEN SOURCE PARTS OF ONLINE SERVICES CODE (2 MINUTE READ)
[6] 

 Chinese AI lab DeepSeek plans to open source portions of its online
services' code as part of an â€œopen source weekâ€ event. 

ğŸ§  

RESEARCH & INNOVATION

 SIGLIP2 (18 MINUTE READ) [7] 

 SigLIP was an immensely popular joint image and text encoder model.
It has now been improved in a number of axes. Most notable is the
substantially improved zero-shot classification performance, which was
the hallmark result of the original CLIP work. 

 STEP-LEVEL CALIBRATION FOR LLM AGENTS (16 MINUTE READ) [8] 

 STeCa is a novel framework designed to improve LLM agents in
long-horizon tasks by automatically identifying and correcting
suboptimal actions. 

 GEMMAX2 TRANSLATION MODEL (HUGGING FACE HUB) [9] 

 With modern post-training techniques, this 2B model trained on Gemma
achieves state-of-the-art translation performance between 28 different
languages. 

ğŸ§‘â€ğŸ’» 

ENGINEERING & RESOURCES

 MOONLIGHT 16B MUON TRAINED MODEL (GITHUB REPO) [10] 

 This is the first (public) large scale model trained with the Muon
optimizer. It was trained for 5.7T tokens and is a very similar
architecture to DeepSeek v3. 

 TRITON IMPLEMENTATION OF NAIVE SPARSE ATTENTION (GITHUB REPO) [11] 

 The DeepSeek NSA paper made waves last week for its scalable and
efficient long context attention algorithm. However, there was no code
available. This work is a Triton replication that can be slotted into
any PyTorch codebase. 

 LLM DEPLOYMENT WITH OMNISERVE (GITHUB REPO) [12] 

 OmniServe offers a unified framework for efficient large-scale LLM
deployment, combining innovations in low-bit quantization and sparse
attention to enhance both speed and cost-effectiveness. 

ğŸ 

MISCELLANEOUS

 CUDA FOR PYTHON PROGRAMMERS (35 MINUTE READ) [13] 

 A great introduction to CUDA programming for those familiar with
Python programming. 

 US AI SAFETY INSTITUTE BUDGET CUTS (11 MINUTE READ) [14] 

 This article explores the potential impacts of funding cuts to the US
AI Safety Institute, including implications for national security, AI
research, and international competition. 

 MICROSOFT PREPARES FOR OPENAI'S GPT-5 MODEL (9 MINUTE READ) [15] 

 Microsoft is preparing to host OpenAI's GPT-4.5 model as early as
next week, with a more significant GPT-5 release anticipated by late
May. The GPT-5 system will integrate OpenAI's new o3 reasoning model,
aiming to create a unified AI functionality. Both releases align with
key tech events, such as Microsoft Build and Google I/O, underscoring
Microsoft's strategic positioning in the AI space. 

âš¡ 

QUICK LINKS

 PARALLELIZING MUON (7 MINUTE READ) [16] 

 Various novel strategies to parallelize the up-and-coming Muon
optimizer. 

 CHATGPT REACHES 400M WEEKLY ACTIVE USERS (1 MINUTE READ) [17] 

 ChatGPT has reached 400 million weekly active users, doubling its
count since August 2024. 

 GOOGLE'S AI CO-SCIENTIST IS 'TEST-TIME SCALING' ON STEROIDS. WHAT
THAT MEANS FOR RESEARCH (5 MINUTE READ) [18] 

 Google has enhanced its Gemini 2.0 LLM to generate scientific
hypotheses significantly faster than human researchers. 

Love TLDR? Tell your friends and get rewards!

 Share your referral link below with friends to get free TLDR swag! 

 https://refer.tldr.tech/34c90d5b/2 [19] 

		 Track your referrals here. [20] 

Want to advertise in TLDR? ğŸ“°

 If your company is interested in reaching an audience of AI
professionals and decision makers, you may want to ADVERTISE WITH US
[21]. 

Want to work at TLDR? ğŸ’¼

 APPLY HERE [22] or send a friend's resume to jobs@tldr.tech and get
$1k if we hire them! 

 If you have any comments or feedback, just respond to this email! 

Thanks for reading, 
Andrew Tan [23], Ali Aminian [24] & Andrew Carr [25] 

 Manage your subscriptions [26] to our other newsletters on tech,
startups, and programming. Or if TLDR AI isn't for you, please
unsubscribe [27]. 

 

Links:
------
[1] https://tldr.tech/ai?utm_source=tldrai
[2] https://advertise.tldr.tech/?utm_source=tldrai&utm_medium=newsletter&utm_campaign=advertisetopnav
[3] https://a.tldrnewsletter.com/web-version?ep=1&lc=041b8714-96a1-11ed-9899-3729ef006681&p=56946d08-f298-11ef-82b7-ff57aa560fd8&pt=campaign&t=1740406077&s=e2d3b731673e3104d861f078f735f7aece5ddef22f548b83d65110ed73eab4f0
[4] https://techcrunch.com/2025/02/21/report-openai-plans-to-shift-compute-needs-from-microsoft-to-softbank/?utm_source=tldrai
[5] https://ai.meta.com/blog/orakl-oncology-dinov2-accelerating-cancer-treatment/?utm_source=tldrai
[6] https://techcrunch.com/2025/02/21/deepseek-to-open-source-parts-of-online-services-code/?utm_source=tldrai
[7] https://github.com/google-research/big_vision/blob/main/big_vision/configs/proj/image_text/README_siglip2.md?utm_source=tldrai
[8] https://arxiv.org/abs/2502.14276v1?utm_source=tldrai
[9] https://huggingface.co/ModelSpace/GemmaX2-28-2B-v0.1?utm_source=tldrai
[10] https://github.com/MoonshotAI/Moonlight?utm_source=tldrai
[11] https://github.com/fla-org/native-sparse-attention?utm_source=tldrai
[12] https://github.com/mit-han-lab/omniserve?utm_source=tldrai
[13] https://www.pyspur.dev/blog/introduction_cuda_programming?utm_source=tldrai
[14] https://www.hpbl.co.in/market/us-ai-safety-institute-could-face-big-cuts-implications-challenges-and-future-prospects/?utm_source=tldrai
[15] https://www.theverge.com/notepad-microsoft-newsletter/616464/microsoft-prepares-for-openais-gpt-5-model?utm_source=tldrai
[16] https://main-horse.github.io/posts/parallelizing-muon/?utm_source=tldrai
[17] https://www.engadget.com/ai/chatgpt-reaches-400m-weekly-active-users-203635884.html?utm_source=tldrai
[18] https://www.zdnet.com/article/googles-ai-co-scientist-is-test-time-scaling-on-steroids-what-that-means-for-research/?utm_source=tldrai
[19] https://refer.tldr.tech/34c90d5b/2
[20] https://hub.sparklp.co/sub_46c6316534f5/2
[21] https://advertise.tldr.tech/?utm_source=tldrai&utm_medium=newsletter&utm_campaign=advertisecta
[22] https://jobs.ashbyhq.com/tldr.tech
[23] https://twitter.com/andrewztan
[24] https://www.linkedin.com/in/aliiaminian/
[25] https://twitter.com/andrew_n_carr
[26] https://tldr.tech/ai/manage?email=blockchaincryptologue%40gmail.com
[27] https://a.tldrnewsletter.com/unsubscribe?ep=1&l=eedf6b14-3de3-11ed-9a32-0241b9615763&lc=041b8714-96a1-11ed-9899-3729ef006681&p=56946d08-f298-11ef-82b7-ff57aa560fd8&pt=campaign&pv=4&spa=1740405637&t=1740406077&s=42040e5414c99bc80499d59847fd41365906d4eda1226731caab2b31008dd226