# Articles TLDR AI 03-03-2023

How OpenAI CTO Mira Murati became one of tech‚Äôs most influential
innovators.¬† 

Sign Up [https://tldr.tech/ai?utm_source=tldr]|Jobs
[https://tldr.tech/jobs]|Advertise
[https://danni763618.typeform.com/to/K4Gdz1?utm_source=tldrai&utm_medium=newsletter#newsletter=ai]|View
Online
[https://actions.tldrnewsletter.com/web-version?ep=1&lc=041b8714-96a1-11ed-9899-3729ef006681&p=28809a2a-b999-11ed-be03-99942e798a26&pt=campaign&t=1677852360&s=232f7cbcffe9e4ac965202c3e02b250cb13ddda8ce9d5578391661824edecded]


		TLDR 

DAILY UPDATE 2023-03-03

üöÄ 

HEADLINES & LAUNCHES

FORD ANNOUNCES NEW SELF DRIVING DIVISION ‚ÄúLATITUDE AI‚Äù (3 MINUTE
READ)
[https://media.ford.com/content/fordmedia/fna/us/en/news/2023/03/02/ford-establishes-latitude-ai-to-develop-future-automated-driving.html?utm_source=tldrai]


Ford is committed to the future of autonomous vehicles and this
announcement confirms that. The 550 person Pittsburgh based team will
continue working on technologies that have shipped in Ford products
while also doing long term research towards fully autonomous vehicles.
Long standing leaders in the field will lead the group in various
capacities. 

GOOGLE CLOUD CEO RALLYING CRY ABOUT CONTINUED AI COMPETENCY (2 MINUTE
READ) [https://archive.ph/GijmU?utm_source=tldrai] 

With the AI race heating up, Google is feeling the pressure. In a
recent internal meeting the Google Cloud CEO said ‚ÄúThe game is never
over in the first minute‚Äù and urged employees to work as a team to
continue to improve AI capabilities. He talked about what the history
books would say about Google navigating this time period and expressed
optimism about the future of search. 

üß† 

RESEARCH & INNOVATION

LONG CONVOLUTIONS AND CLEVER TOKEN MIXING SCALES TO BE 100X FASTER AT
64K TOKENS (60 MINUTE READ)
[https://arxiv.org/abs/2302.10866?utm_source=tldrai] 

Another paper from the systems group at Stanford working on improving
language modeling abilities for long context. They work to build a
subquadratic attention replacement and build on much of their recent
work in state space models and long convolutions work. They introduce
the ‚ÄúHyena Hierarchy‚Äù which is a drop in replacement for
attention, while reducing FLOPs, and improving long context scaling.
This is an exciting next step and worth a read. 

UNLIMITED-SIZE DIFFUSION RESTORATION (9 MINUTE READ)
[https://arxiv.org/abs/2303.00354?utm_source=tldrai] 

The paper discusses the use of diffusion models for zero-shot image
restoration and proposes solutions for handling images of arbitrary
sizes. The current methods only deal with fixed-size images, but the
proposed approach uses Mask-Shift Restoration to address local
incoherence and Hierarchical Restoration to alleviate out-of-domain
issues. These parameter-free approaches can be used not only for image
restoration but also for image generation of unlimited sizes, making
them a potential general tool for diffusion models. 

STRAIT: NON-AUTOREGRESSIVE GENERATION WITH STRATIFIED IMAGE
TRANSFORMER (15 MINUTE READ)
[https://arxiv.org/abs/2303.00750?utm_source=tldrai] 

The paper proposes a non-autoregressive (NAR) generative model called
Stratified Image Transformer (StraIT) that outperforms existing
autoregressive (AR) and diffusion models (DMs) in high-quality image
synthesis. StraIT leverages the hierarchical nature of images to
encode visual tokens into stratified levels, which alleviates modeling
difficulty and lifts the generative power of NAR models. The
experiments show that StraIT achieves FID scores of 3.96 at 256√ó256
resolution on ImageNet without leveraging any guidance in sampling or
auxiliary image classifiers. 

üßë‚Äçüíª 

ENGINEERING & RESOURCES

MONOCULAR DEPTH ESTIMATION USING DIFFUSION MODELS (GITHUB REPO)
[/%E2%80%8B%E2%80%8Bhttps://depth-gen.github.io/?utm_source=tldrai] 

The authors propose a denoising diffusion model-based approach for
monocular depth estimation. They introduce innovations to tackle noisy
and incomplete depth maps, and leverage pre-training for supervised
learning. Their DepthGen model achieves state-of-the-art performance
and represents depth ambiguity naturally. The model's imputation
support and zero-shot performance enable a simple text-to-3D pipeline.


BETTER CONTROL THAN CONTROLNET (HUGGINGFACE SPACE)
[https://huggingface.co/spaces/weizmannscience/multidiffusion-region-based?utm_source=tldrai]


Another novel approach to controlling the geometric output of a
text-to-image model. This time you can specify multiple regions to
control. The general code is not yet available, but you can test the
model out in this space. 

COLLAGE DIFFUSION: PRECISE CONTROL OVER COLLAGE-CONDITIONAL IMAGE
GENERATION (25 MINUTE READ)
[https://arxiv.org/abs/2303.00262?utm_source=tldrai] 

The paper proposes Collage Diffusion, a collage-conditional diffusion
algorithm that enables precise control over the spatial arrangement
and visual attributes of objects in generated images. By modifying the
text-image cross-attention with alpha masks and learning specialized
text representations per layer, users can edit individual components
of generated images and control image harmonization on a
layer-by-layer basis. Collage Diffusion generates globally harmonized
images that maintain desired object locations and visual
characteristics better than prior approaches. 

üéÅ 

MISCELLANEOUS

ELEUTHERAI RETROSPECTIVE (6 MINUTE READ)
[https://blog.eleuther.ai/year-two-preface/?utm_source=tldrai] 

One of the top open science collaboratives in ML, Eleuther has made
many contributions to the field over the past year and a half. They
have published 28 papers, 10 different models, and dozens of code
bases. Many of the most exciting developments such as RWKV, GPTNeo,
and open replications of AlphaFold are coming from this group. Read
more here about what they‚Äôre working on and what‚Äôs coming next. 

20B FLAN UL2 MODEL RELEASED - FULLY OPEN SOURCE WITH NO RESTRICTIONS
(7 MINUTE READ)
[https://www.yitay.net/blog/flan-ul2-20b?utm_source=tldrai] 

With a context length of 2048 tokens, this instruction tuned model is
an excellent foundation model for text generation. With improved CoT,
in context learning, and general performance (as much as 7.4% over
FlanT5-xxl) this model is a great step forward in open source language
models. This model uses the UL2 objective which is a mixture of
denoisers and has shown impressive performance at general language
modeling. Importantly, they also remove the need for cumbersome mode
tokens by an additional 100k steps of training before the Flan
instruction tuning process. 

INSIDE THE RISE OF OPENAI CTO MIRA MURATI (17 MINUTE READ)
[https://archive.is/9t9gB?utm_source=tldrai] 

This article is a deep dive into how OpenAI CTO Mira Murati became one
of tech‚Äôs most influential innovators. 

‚ö° 

QUICK LINKS

ROMANIA UNVEILS WORLD‚ÄôS FIRST AI GOVERNMENT ‚ÄúADVISOR‚Äù (2 MINUTE
READ)
[https://interestingengineering.com/innovation/romania-unveils-worlds-first-ai-advisor?utm_source=tldrai]


The Romanian government has unveiled "Ion," an artificial intelligence
(AI) based platform built to record Romanians' voices and opinions and
use them to guide state policy decisions. 

OPENAI PRICING THREAD (TWITTER THREAD)
[https://threadreaderapp.com/thread/1631346679893958658.html?utm_source=tldrai]


Yesterday‚Äôs 90% price drop on the ChatGPT API ‚Äì aka
"gpt-3.5-turbo" ‚Äì is another before & after moment in AI. 

PROMPTCRAFT-ROBOTICS (GITHUB REPO)
[https://github.com/microsoft/PromptCraft-Robotics?utm_source=tldrai] 

PromptCrafts-Robotics is a community for people to test and share
interesting prompting examples for LLMs within the robotics domain. 

NEBULLVM (GITHUB REPO)
[https://github.com/nebuly-ai/nebullvm?utm_source=tldrai] 

Nebullvm is an ecosystem of plug and play modules to optimize the
performance of your AI systems. 

If you are in a hiring position, you may want to HIRE AI TALENT
THROUGH OUR FREE JOB BOARD [https://tldr.tech/employer/sign-up]. 

If your company is interested in reaching an audience of AI
decision-makers, researchers, and engineers, you may want to ADVERTISE
WITH US
[https://danni763618.typeform.com/to/K4Gdz1?utm_source=tldrai&utm_medium=newsletter#newsletter=ai].


If you have any comments or feedback, just respond to this email! 

Thanks for reading, 
Andrew Tan (@ANDREWZTAN [https://twitter.com/andrewztan]) & Andrew
Carr (@ANDREW_N_CARR [https://twitter.com/andrew_n_carr]) 

If you don't want to receive future editions of TLDR AI, please¬†click
here to unsubscribe
[https://actions.tldrnewsletter.com/unsubscribe?ep=1&l=eedf6b14-3de3-11ed-9a32-0241b9615763&lc=041b8714-96a1-11ed-9899-3729ef006681&p=28809a2a-b999-11ed-be03-99942e798a26&pt=campaign&pv=4&spa=1677852018&t=1677852360&s=b512d60fc0212c064c27ff2e8b90b91e8132c797b0b68842f4a6baae55c1ff95].


¬†