# Articles TLDR AI 11-11-2024

OpenAI's next major model, code-named "Orion," reportedly shows less
improvement over previous models, suggesting a slowdown in AI
advancement.Â â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ Â â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ 


 Sign Up [1] |Advertise [2]|View Online [3] 

		TLDR 

		TOGETHER WITH [You.com] [4]

TLDR AI 2024-11-11

 HOW COMPANIES ARE USING CUSTOM AI AGENTS TO BOOST PRODUCTIVITY 10X
(SPONSOR) [4] 

 You might have heard the chatter about AI agents. But what's behind
this recent trend, and who's already on board?

You.com's free whitepaper [4] reveals exactly how marketing, sales,
and analytics departments are using AI agents to save time, improve
output quality, and optimize workflows. The paper details:

âœ… Three simple steps to create custom AI agents [4] for your
domain-specific workflows.

âœ… Dozens of use-cases across three sectors.

âœ… Industry breakdowns of where AI agents are being deployed â€“ and
how often.

Read the whitepaper [4]

ğŸš€ 

HEADLINES & LAUNCHES

 MODAL BUYS TIDBYT (6 MINUTE READ) [5] 

 The first acquisition by the elastic scaling GPU company. Modal
bought Tidbyt, an NYC-based hardware company, for the in-house talent
of the team around infrastructure and containerization. 

 OPENAI FACES AI IMPROVEMENT SLOWDOWN (2 MINUTE READ) [6] 

 OpenAI's next major model, code-named "Orion," reportedly shows less
improvement over previous models, suggesting a slowdown in AI
advancement. To tackle this, OpenAI has formed a foundations team
focused on enhancing models with alternative methods, such as
synthetic data training and post-training adjustments, as the
availability of new data has decreased. 

 WORLD'S LARGEST OPEN-SOURCE MODEL (4 MINUTE READ) [7] 

 Near Protocol has announced plans to create a massive 1.4 trillion
parameter open-source AI model. It aims to surpass existing models
like Meta's Llama. 

ğŸ§  

RESEARCH & INNOVATION

 FRONTIER MATH BENCHMARK (21 MINUTE READ) [8] 

 Epoch AI has released a new challenging mathematics benchmark. Most
frontier models are unable to solve more than 2% of the problems. 

 BITNET A4.8: 4-BIT ACTIVATIONS FOR 1-BIT LLMS (30 MINUTE READ) [9] 

 One of the key challenges with 1.58bit LLMs was the lack of hardware
acceleration support. This work proposes 4.8bit activations to take
advantage of the INT4/FP4 kernels in new hardware. It comes at no
runtime cost. 

 SUPERCHARGING CLIP WITH LLMS (3 MINUTE READ) [10] 

 LLM2CLIP combines CLIP's visual and textual alignment with the
advanced language understanding of LLMs. 

ğŸ§‘â€ğŸ’» 

ENGINEERING & RESOURCES

 TORCH COMPATIBLE MUON OPTIMIZER (GITHUB REPO) [11] 

 Muon was the optimizer used for the GPT-2 training record. It is a
momentum adapted SGD style method. This repository contains an
implementation that can be dropped in for AdamW. 

 MOCHI VIDEO MODEL WITH OPTIMIZED INFERENCE (GITHUB REPO) [12] 

 Mochi is the best open source text-to-video model. On launch, it took
8 H100s to run. Now, thanks to the community, it can be run on a
single 48GB L40 with no loss in quality. 

 TRAINABLE PYTORCH REPRODUCTION OF ALPHAFOLD3 (GITHUB REPO) [13] 

 Protenix is a working and trainable reproduction of AlphaFold3, a
protein folding project from DeepMind. It was written by Bytedance's
'AI for Science' team. 

ğŸ 

MISCELLANEOUS

 LLAMAPREVIEW (2 MINUTE READ) [14] 

 LlamaPReview is an AI assistant for GitHub that offers one-click
installation and auto-reviews of pull requests with context-aware
analysis. It supports multiple programming languages and integrates
with GitHub Actions, providing insightful feedback directly on PRs.
Currently available for free, it enhances code quality by identifying
issues and suggesting optimizations. 

 SMOLLM2 (2 MINUTE READ) [15] 

 Hugging Face's SmolLM2 is a compact language model family with sizes
ranging from 135M to 1.7B parameters trained on 11 trillion tokens.
These models efficiently run on-device and support various tasks, with
weights available under the Apache 2 license. Quantized models like
the 1.7GB and 138MB versions provide diverse flexibility for different
computational needs. 

 EMBEDDINGS ARE UNDERRATED (9 MINUTE READ) [16] 

 Machine learning embeddings can transform technical writing by
enabling mathematical comparisons of arbitrary text, improving
features like recommendation systems with semantic similarities. They
place text within a multi-dimensional space, providing intuitive
semantic relationships, useful for tasks like identifying related
content. Docs site owners who offer embeddings for their content could
foster innovative applications from their communities. 

âš¡ 

QUICK LINKS

 SAMSUNG DEBUTS AI-POWERED 'NEXT-GENERATION BIXBY,' BUT YOU CAN'T USE
IT YET (3 MINUTE READ) [17] 

 Samsung has launched a "next-generation Bixby" with enhanced AI
capabilities on the Galaxy W25 and W25 Flip in China. 

 EVEN MICROSOFT NOTEPAD IS GETTING AI TEXT EDITING NOW (2 MINUTE READ)
[18] 

 Microsoft is integrating AI-powered text editing in Notepad, enabling
users to rephrase, adjust tone, and modify text length through a
feature called Rewrite. 

 AI FOR REAL-TIME FUSION PLASMA BEHAVIOR PREDICTION AND MANIPULATION
(6 MINUTE READ) [19] 

 A new multimodal machine learning methodology enhances
super-resolution data for better analysis of complex fusion plasma
phenomena, such as Edge Localized Modes (ELM), aiding in the
stabilization of future fusion reactors. 

Love TLDR? Tell your friends and get rewards!

 Share your referral link below with friends to get free TLDR swag! 

 https://refer.tldr.tech/34c90d5b/2 [20] 

		 Track your referrals here. [21] 

Want to advertise in TLDR? ğŸ“°

 If your company is interested in reaching an audience of AI
professionals and decision makers, you may want to ADVERTISE WITH US
[22]. 

 If you have any comments or feedback, just respond to this email! 

Thanks for reading, 
Andrew Tan & Andrew Carr 

If you don't want to receive future editions of TLDR AI, please
unsubscribe from TLDR AI [23] or manage all of your TLDR newsletter
subscriptions [24]. 

 

Links:
------
[1] https://tldr.tech/ai?utm_source=tldrai
[2] https://advertise.tldr.tech/?utm_source=tldrai&utm_medium=newsletter&utm_campaign=advertisetopnav
[3] https://a.tldrnewsletter.com/web-version?ep=1&lc=041b8714-96a1-11ed-9899-3729ef006681&p=f1581236-a01d-11ef-821e-fb1b20add704&pt=campaign&t=1731334063&s=73f8ade7ac964a401af87a0f9c3b67107e712546806154d507838908bf8f7997
[4] https://home.you.com/customaiagentswp?utm_campaign=Agents%20by%20Function&utm_source=Paid_TLDR&utm_medium=Paid_Email&utm_content=TLDR_AI_Pri_11Nov24
[5] https://modal.com/blog/tidbyt-is-joining-modal?utm_source=tldrai
[6] https://techcrunch.com/2024/11/09/openai-reportedly-developing-new-strategies-to-deal-with-ai-improvement-slowdown/?utm_source=tldrai
[7] https://cointelegraph.com/news/near-plans-to-create-world-s-largest-1-4-t-parameter-open-source-ai-model?utm_source=tldrai
[8] https://epochai.org/frontiermath?utm_source=tldrai
[9] https://arxiv.org/abs/2411.04965?utm_source=tldrai
[10] https://microsoft.github.io/LLM2CLIP/?utm_source=tldrai
[11] https://github.com/KellerJordan/Muon?utm_source=tldrai
[12] https://github.com/xdit-project/mochi-xdit?utm_source=tldrai
[13] https://github.com/bytedance/Protenix?utm_source=tldrai
[14] https://github.com/marketplace/llamapreview?utm_source=tldrai
[15] https://simonwillison.net/2024/Nov/2/smollm2/?utm_source=tldrai
[16] https://technicalwriting.dev/data/embeddings.html?utm_source=tldrai
[17] https://9to5google.com/2024/11/06/samsung-next-generation-bixby-china/?utm_source=tldrai
[18] https://www.theverge.com/2024/11/6/24289707/microsoft-notepad-ai-text-editing-rewrite?utm_source=tldrai
[19] https://control.princeton.edu/machine-learning-for-rt-profile-control-in-tokamaks/?utm_source=tldrai
[20] https://refer.tldr.tech/34c90d5b/2
[21] https://hub.sparklp.co/sub_46c6316534f5/2
[22] https://advertise.tldr.tech/?utm_source=tldrai&utm_medium=newsletter&utm_campaign=advertisecta
[23] https://a.tldrnewsletter.com/unsubscribe?ep=1&l=eedf6b14-3de3-11ed-9a32-0241b9615763&lc=041b8714-96a1-11ed-9899-3729ef006681&p=f1581236-a01d-11ef-821e-fb1b20add704&pt=campaign&pv=4&spa=1731333708&t=1731334063&s=90188bb1b9818b1bff8f0b22150d84cce4b916fbf421c15b7d4ea7faa6db17ed
[24] https://tldr.tech/ai/manage?email=blockchaincryptologue%40gmail.com