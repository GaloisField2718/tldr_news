# Articles TLDR AI 17-02-2026

Qwen3.5-397B-A17B is the first model in the Qwen3.5 series. The native
vision-language model demonstrates outstanding results in reasoning
and
codingÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ Â â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ â€ŒÂ 


 Sign Up [1] |Advertise [2]|View Online [3] 

		TLDR 

		TOGETHER WITH [Voxel51] [4]

TLDR AI 2026-02-17

 CUT ANNOTATION COSTS BY 90% WITH FEEDBACK-DRIVEN PIPELINES (SPONSOR)
[4] 

 95% of labeled data never gets used [4], and most teams spend 5-7
review cycles before datasets are production-ready.

The problem? Disconnected workflows between annotation tools, data
curation, and model evaluation create endless handoffs and wasted
iteration cycles.Â 

This hands-on workshop on February 18th shows you how to fix it.
You'll learn how to:

 	* Build annotation pipelines that start with real model failures and
data gaps
 	* Use zero-shot techniques to label only high-value data
 	* Structure human-in-the-loop workflows that cut annotation costs
while improving model performance
 	* Create a closed loop from annotation to QA to model training

You'll also get this step-by-step guide [5] for implementing a
data-centric annotation workflow.

REGISTER FOR THE FEBRUARY 18TH WORKSHOP â†’ [6]

ğŸš€ 

HEADLINES & LAUNCHES

 QWEN3.5: TOWARDS NATIVE MULTIMODAL AGENTS (40 MINUTE READ) [7] 

 Qwen3.5-397B-A17B is the first model in the Qwen3.5 series. The
native vision-language model demonstrates outstanding results in
reasoning, coding, agent capabilities, and multimodal understanding.
It uses an innovative hybrid architecture that fuses linear attention
with a sparse mixture-of-experts. While it contains 397 billion
parameters, only 17 billion are activated per forward pass. The model
supports 201 languages and dialects. 

 INTRODUCING MANUS IN YOUR CHAT: YOUR PERSONAL AGENT, EVERYWHERE YOU
ARE (3 MINUTE READ) [8] 

 Manus Agents is a new way to access and use Manus directly inside
messaging apps. Telegram is currently the only supported app, with
more platforms coming soon. The agent features few reasoning, tools,
and multi-step task execution. The feature makes agents accessible
wherever users are. 

 MICROSOFT TESTS RESEARCHER AND ANALYST AGENTS IN COPILOT (2 MINUTE
READ) [9] 

 Microsoft is testing new Researcher and Analyst agents integrated
into Copilot's upcoming "Tasks" feature. This feature will allow users
to schedule complex prompts, leveraging OpenAI and o3-mini models for
research and data analysis. The addition of an "Auto" mode aims to
streamline task automation, potentially differentiating Copilot in
productivity use cases. 

ğŸ§  

DEEP DIVES & ANALYSIS

 ON DWARKESH PATEL'S 2026 PODCAST WITH DARIO AMODEI (11 MINUTE READ)
[10] 

 Anthropic's CEO, Dario Amodei, expects 'geniuses in a data center' to
show up within a few years. While Anthropic's actions do not seem to
fully reflect this optimism, its caution is necessary. This article
contains notes from a recent podcast where Amodei discusses China,
export controls, democracy, AI policy, AI risks, and continual
learning. 

 WHY I DON'T THINK AGI IS IMMINENT (12 MINUTE READ) [11] 

 AGI is likely possible, but it probably won't come from
Transformer-based models. Transformers are very powerful, but they
have fundamental limitations. Solving these limitations could take
decades. This isn't to say that LLMs aren't useful - the current
technology is already fundamentally changing society. 

 HOW PERSISTENT IS THE INFERENCE COST BURDEN? (10 MINUTE READ) [12] 

 Inference costs may not be that much of a bottleneck for AI progress.
The cost to reach a given capability level falls fast, so the
inference cost burden is more transient than it might appear from
looking at only frontier models at launch. The data on RL scaling is
still thin, so it is difficult to draw conclusions yet. It will be
interesting to see how quickly cheaper models catch up to frontier
capability levels, and how inference costs for fixed tasks decrease
over time. 

ğŸ§‘â€ğŸ’» 

ENGINEERING & RESEARCH

 WHAT BOTTLENECK? 50% OF AGENTIC AI PROJECTS ARE IN PRODUCTION
(SPONSOR) [13] 

 Autonomous operations are rapidly expanding, and 74% of enterprises
expect AI budgets to rise further in 2026. Dynatrace surveyed [13]
900+ global decision-makers about how they're operationalizing agentic
AI, with observability as the foundation for trust and control. See
where the market is headed with this in-depth research report [13] 

 HOW MUCH ARE AI REASONING GAINS CONFOUNDED BY EXPANDING THE TRAINING
CORPUS 10,000X? (5 MINUTE READ) [14] 

 Benchmark performance gives biased estimates of out-of-distribution
generalization if LLM training data is polluted with benchmark test
data. Typical decontamination filters fail to detect semantic
duplicates. This suggests that recent benchmark gains are confounded -
the prevalence of soft contamination means gains reflect both genuine
compatibility improvements and the accumulation of test data and
effective test data in the growing training corpora. 

 ZVEC: A LIGHTWEIGHT, LIGHTNING-FAST, IN-PROCESS VECTOR DATABASE
(GITHUB REPO) [15] 

 Alibaba's ZVEC is an open-source, in-process vector database enabling
rapid, scalable similarity searches using Alibaba's PROXIMA engine. It
supports dense and sparse vectors with hybrid searches and can be
deployed across various platforms, including notebooks and edge
devices. Installation is straightforward via Python or Node.js,
offering a lightweight solution for handling vector data efficiently. 

 ANNOUNCING SPREADSHEET ARENA (2 MINUTE READ) [16] 

 Spreadsheet Arena is an open platform for evaluating LLM-generated
spreadsheets. Formatting and structure often influence user preference
more than formula complexity. There are significant differences in
domain-specific preferences, with academic models suffering from heavy
formatting and finance models benefiting from professional color
coding. Crowd preferences often diverge from expert ratings,
particularly in color coding and formatting. 

ğŸ 

MISCELLANEOUS

 MICRON IS SPENDING $200 BILLION TO BREAK THE AI MEMORY BOTTLENECK (9
MINUTE READ) [17] 

 Micron Technology, the largest American maker of memory chips, is
rushing to add manufacturing capacity to break the memory bottleneck.
The company is spending $50 billion to more than double the size of
its 450-acre campus. It will build two new chip factories, the first
of which is expected to start production of DRAM in mid-2027. Micron
also recently broke ground on a $100 billion fab complex in New York,
and it announced a $9.6 billion fab investment in Japan last year. 

 FLAPPING AIRPLANES ON THE FUTURE OF AI: 'WE WANT TO TRY REALLY
RADICALLY DIFFERENT THINGS' (20 MINUTE READ) [18] 

 Flapping Airplanes aims to revolutionize AI by developing
data-efficient training methods, reducing reliance on vast datasets.
Backed by $180 million, the founders emphasize diverging from
traditional methods, drawing inspiration from the human brain without
replicating it exactly. They focus on creativity and fresh
perspectives, employing a team oriented towards groundbreaking
research rather than incremental improvements. 

 ON ANTHROPIC'S CONSUMER MARKETING (4 MINUTE READ) [19] 

 Anthropic has a big consumer marketing problem. Its story, while well
known in Silicon Valley, isn't widely heard or legible to the greater
cultural conscience. It is puzzling how a company so good at
aesthetics and narrative engineering can be so bad at this. 

âš¡ 

QUICK LINKS

 STARTUP SUPPORT THAT DELIVERS RESULTS (SPONSOR) [20] 

 Let MongoDB for Startups partner with you as you build the next big
thing with the tools, support, and go-to-market opportunities you need
to accelerate from idea to IPO. Get started here. [21] 

 THE LONG TAIL OF LLM-ASSISTED DECOMPILATION (17 MINUTE READ) [22] 

 LLMs can assist with decompiling Nintendo 64 games up to a certain
point - this post describes a developer's attempt, how their workflow
evolved as the project matured, what helped, and where they're
currently stuck. 

 YOU SEE TECH AND AI EVERYWHERE, BUT IN THE PRODUCTIVITY STATISTICS (1
MINUTE READ) [23] 

 US productivity increased roughly 2.7% for 2025, a near doubling from
the sluggish 1.4% annual average that characterized the past decade. 

 Q: I WANT TO WASH MY CAR. THE CAR WASH IS 50 METERS AWAY. SHOULD I
WALK OR DRIVE? (1 MINUTE READ) [24] 

 Nearly all models tested responded that they should walk. 

 WILL REWARD-SEEKERS RESPOND TO DISTANT INCENTIVES? (10 MINUTE READ)
[25] 

 AIs optimized as â€œreward-seekersâ€ might be influenced not just by
local training incentives but also by distant retroactive rewards or
simulated scenarios administered later or by powerful actors. 

 THE SCARCITY TRAP: WHY AI STILL FEELS LIKE A METERED UTILITY (14
MINUTE READ) [26] 

 AI is constrained by silicon, supply chains, and economics. 

 THE ECONOMICS OF LLM INFERENCE: BATCH SIZES, LATENCY TIERS, AND WHY
MODEL LABS HAVE AN ADVANTAGE (14 MINUTE READ) [27] 

 Model labs have a structural cost advantage that pure inference
providers will struggle to match. 

Love TLDR? Tell your friends and get rewards!

 Share your referral link below with friends to get free TLDR swag! 

 https://refer.tldr.tech/34c90d5b/2 [28] 

		 Track your referrals here. [29] 

Want to advertise in TLDR? ğŸ“°

 If your company is interested in reaching an audience of AI
professionals and decision makers, you may want to ADVERTISE WITH US
[30]. 

Want to work at TLDR? ğŸ’¼

 APPLY HERE [31], CREATE YOUR OWN ROLE [32] or send a friend's resume
to jobs@tldr.tech and get $1k if we hire them! TLDR is one of INC.'S
BEST BOOTSTRAPPED BUSINESSES [33] of 2025. 

 If you have any comments or feedback, just respond to this email! 

Thanks for reading, 
Andrew Tan [34], Ali Aminian [35], & Jacob Turner [36] 

 Manage your subscriptions [37] to our other newsletters on tech,
startups, and programming. Or if TLDR AI isn't for you, please
unsubscribe [38]. 

 

Links:
------
[1] https://tldr.tech/ai?utm_source=tldrai
[2] https://advertise.tldr.tech/?utm_source=tldrai&utm_medium=newsletter&utm_campaign=advertisetopnav
[3] https://a.tldrnewsletter.com/web-version?ep=1&lc=041b8714-96a1-11ed-9899-3729ef006681&p=6c35d588-0bfc-11f1-97d0-d33e328c56cb&pt=campaign&t=1771337577&s=d7dd03e3374dc284a75695986ae2552bc138e8697f03c6583d8fa7bcc3059719
[4] https://link.voxel51.com/tl-dr-HA-blog/
[5] https://link.voxel51.com/tldr-HA-tutorial/
[6] https://link.voxel51.com/tldr-HA-launch/
[7] https://qwen.ai/blog?id=qwen3.5&utm_source=tldrai
[8] https://manus.im/blog/manus-agents-telegram?utm_source=tldrai
[9] https://www.testingcatalog.com/microsoft-tests-researcher-and-analyst-agents-in-copilot-tasks/?utm_source=tldrai
[10] https://thezvi.wordpress.com/2026/02/16/on-dwarkesh-patels-2026-podcast-with-dario-amodei/?utm_source=tldrai
[11] https://dlants.me/agi-not-imminent.html?utm_source=tldrai
[12] https://epochai.substack.com/p/how-persistent-is-the-inference-cost?utm_source=tldrai
[13] https://www.dynatrace.com/info/reports/the-pulse-of-agentic-ai-in-2026/?utm_medium=email&utm_source=tldr&utm_campaign=cloud-ai-observability-pulse-agentic-ai-2026&utm_content=none&utm_term=021726
[14] https://threadreaderapp.com/thread/2023384075537432662.html?utm_source=tldrai
[15] https://github.com/alibaba/zvec?utm_source=tldrai
[16] https://www.meridian.ai/blog/all/spreadsheet-arena?utm_source=tldrai
[17] https://links.tldrnewsletter.com/KPTt0g
[18] https://techcrunch.com/2026/02/16/flapping-airplanes-on-the-future-of-ai-we-want-to-try-really-radically-different-things/?utm_source=tldrai
[19] https://rohan.ga/blog/anthro_consumer/?utm_source=tldrai
[20] https://fandf.co/4kwvED1?utm_source=tldrai
[21] https://fandf.co/4kwvED1
[22] https://blog.chrislewis.au/the-long-tail-of-llm-assisted-decompilation/?utm_source=tldrai
[23] https://links.tldrnewsletter.com/sKu7GT
[24] https://links.tldrnewsletter.com/PBzJHo
[25] https://www.alignmentforum.org/posts/8cyjgrTSxGNdghesE/will-reward-seekers-respond-to-distant-incentives?utm_source=tldrai
[26] https://ilicigor.substack.com/p/the-scarcity-trap-why-ai-still-feels?utm_source=tldrai
[27] https://mlechner.substack.com/p/the-economics-of-llm-inference-batch?utm_source=tldrai
[28] https://refer.tldr.tech/34c90d5b/2
[29] https://hub.sparklp.co/sub_46c6316534f5/2
[30] https://advertise.tldr.tech/?utm_source=tldrai&utm_medium=newsletter&utm_campaign=advertisecta
[31] https://jobs.ashbyhq.com/tldr.tech
[32] https://jobs.ashbyhq.com/tldr.tech/c227b917-a6a4-40ce-8950-d3e165357871
[33] https://www.linkedin.com/feed/update/urn:li:activity:7401699691039830016/
[34] https://twitter.com/andrewztan
[35] https://www.linkedin.com/in/aliiaminian/
[36] https://www.linkedin.com/in/jacob-turner-7521a8198/
[37] https://tldr.tech/ai/manage?email=blockchaincryptologue%40gmail.com
[38] https://a.tldrnewsletter.com/unsubscribe?ep=1&l=eedf6b14-3de3-11ed-9a32-0241b9615763&lc=041b8714-96a1-11ed-9899-3729ef006681&p=6c35d588-0bfc-11f1-97d0-d33e328c56cb&pt=campaign&pv=4&spa=1771336912&t=1771337577&s=d1c897bb17d7b0db86fed9db35abb956805df4634412e9103b36cc878b7cd8b2