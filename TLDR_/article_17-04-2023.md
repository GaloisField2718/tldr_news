# Articles TLDR  17-04-2023

## Article 1
### [Princeton launches center for language and intelligence (2 minute read)](https://tldr.tech)
### Summary 
 Princeton launches center for language and intelligence (2 minute read)

Recent progress in large language models has been dominated by large industry players. However, many of the key ideas still come from academia. Princeton is hoping to continue contributions to language and intelligence with this new center. TheyE28099re hiring for research scientists, engineers, and postdoc scholars.

## Article 2
### [World's simplest text-to-image model? (6 minute read)](https://tldr.tech)
### Summary 
 World's simplest text-to-image model? (6 minute read)

Laion just released the Paella image generation model. It uses a discrete, token based, latent space and a cross entropy denoising objective. One goal of this project is to make an image synthetics model that almost anyone can understand. Their sampling code is only 12 lines long!

## Article 3
### [Google Rushing To Add AI To Search Engine (5 minute read)](https://tldr.tech)
### Summary 
 Google Rushing To Add AI To Search Engine (5 minute read)

Google is feeling the heat from AI competitors like the new Bing, as Samsung considers making Bing its default search engine. Google's search business, which was worth $162 billion last year, could take a significant hit if Samsung decides to switch. In response, Google is working on an AI-powered search engine project called Magi to provide a more personalized experience. While details on the new search technology are still under wraps, Google has over 160 people working on the project, with plans to roll out new features to the public in the coming months.

## Article 4
### [Scaling, Emergence, and Reasoning in LLMs (6 minute read)](https://tldr.tech)
### Summary 
 Scaling, Emergence, and Reasoning in LLMs (6 minute read)

A presentation given by Jason Wei about how language model performance changes with scale. ItE28099s a lovely discussion about emergent capabilities in these models and what we can do with those new skills. One interesting take-away is that we havenE28099t come close to exhausting all possible tasks, so there could be a variety of skills in the model that we havenE28099t uncovered.

## Article 5
### [So long hyperparameters (38 minute read)](https://tldr.tech)
### Summary 
 So long hyperparameters (38 minute read)

What if we didnE28099t have to tune the pile of hyperparameters we do to make deep learning work? This is a pretty technical paper that presents Automatic Gradient Descent which is a new optimizer that takes into account network architectures and eliminates a set of previously required hyperparameters. They work through all the math thoroughly, and the resulting optimizer seems to be fairly simple. They donE28099t have it working yet for all network architectures, but that feels like only a matter of time.

## Article 6
### [DINOv2: Learning Robust Visual Features without Supervision (18 minute read)](https://tldr.tech)
### Summary 
 DINOv2: Learning Robust Visual Features without Supervision (18 minute read)

Recent breakthroughs in natural language processing have paved the way for foundation models in computer vision, producing all-purpose visual features through self-supervised methods and large, diverse datasets. By utilizing an automatic pipeline for curated data and training a 1-billion-parameter ViT model, researchers have created smaller models that surpass existing all-purpose features in most benchmarks at image and pixel levels.

## Article 7
### [SVMs are better than KNNs for retrieval (Jupyter Notebook)](https://tldr.tech)
### Summary 
 SVMs are better than KNNs for retrieval (Jupyter Notebook)

The former head of AI from Tesla Andrej Karpathy has a gift for teaching difficult concepts. This notebook shows how to use SVMs instead of KNNs to find matches in an embedding index. There is a lot of talk around using embeddings to solve hallucination and this is a concrete example on how to improve performance generally with a different traditional ML method.

## Article 8
### [OpenAI consistency models code (GitHub Repo)](https://tldr.tech)
### Summary 
 OpenAI consistency models code (GitHub Repo)

We wrote recently about the new type of genitive model from OpenAI that is faster than diffusion and more stable than a GAN. They just released code and model checkpoints on a set of small experimental data sets. This model is a cool next step in generative image modeling, and now we can play around with it!

## Article 9
### [SpectFormer: Frequency and Attention is what you need in a Vision Transformer (3 minute read)](https://tldr.tech)
### Summary 
 SpectFormer: Frequency and Attention is what you need in a Vision Transformer (3 minute read)

Combining spectral and multi-headed attention layers in the novel SpectFormer architecture improves transformer performance for image recognition tasks. This approach achieves state-of-the-art accuracy on ImageNet-1K and consistently strong results in transfer learning, object detection, and instance segmentation tasks across various datasets.

## Article 10
### [Cost to train Anthropic's Next model (4 minute read)](https://tldr.tech)
### Summary 
 Cost to train Anthropic's Next model (4 minute read)

Anthropic recently announced plans to spend a billion dollars on training a massive language model. They announced this plan before their strategic partnership with Google, which may offer cheaper compute via their TPU pods. In any case it seems like one of the largest expenses of this endeavor is actually AI researcher salaries, followed closely by compute costs.

## Article 11
### [OpenAssistantE28099s huge chat dataset (HuggingFace Dataset)](https://tldr.tech)
### Summary 
 OpenAssistantE28099s huge chat dataset (HuggingFace Dataset)

There are 161,443 messages with well over 400k quality annotations such as toxicity and quality. This open dataset is intended to help researchers working on alignment of language models.

## Article 12
### [Marketing Co-Pilot AI (Product Launch)](https://tldr.tech)
### Summary 
 Marketing Co-Pilot AI (Product Launch)

Describe your content style E28094 get a personalized list of 60 tweet ideas. Powered by AI. Generate up to 5 content plans per account. Save them in PDF or copy them to Notion.

## Article 13
### [European Parliament Prepares Tough AI Measures (2 minute read)](https://tldr.tech)
### Summary 
 European Parliament Prepares Tough AI Measures (2 minute read)

The European parliament is preparing tough new measures over the use of artificial intelligence, including forcing chatbot makers to reveal if they use copyrighted material.

## Article 14
### [Generating code with tests (GitHub Repo)](https://tldr.tech)
### Summary 
 Generating code with tests (GitHub Repo)

They achieved a new state of the art (already surpassed by Reflexion) on the challenging Human Eval benchmark by first generating tests then determining if the code generated passes those tests.

