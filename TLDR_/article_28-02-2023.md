# Articles TLDR  28-02-2023

## Article 1
### [Voicemod raises $14.5M to ride the generative AI (sonic)boom (5 minute read)](https://tldr.tech)
### Summary 
 Voicemod raises $14.5M to ride the generative AI (sonic)boom (5 minute read)

Voicemod has become the leading creator in real-time voice changing and soundboard technology. Their mission is to enable everyone to express themselves through sound. TheyE28099ve built expressive and immersive audio tools, making it easy to create unique sonic identities and enable interactions with personalized sounds. This will be huge as the podcast, voiceover, and audiobook spaces have blown up the last few years.

## Article 2
### [Deep Graph Library reaches 1.0 (6 minute read)](https://tldr.tech)
### Summary 
 Deep Graph Library reaches 1.0 (6 minute read)

A powerful and useful tool in graph deep learning, DGL is now at version 1.0! Included are hundreds of examples of state of the art graph networks, baselines, and various graph editing utilities. They also have modular building blocks for message passing algorithms and Multi-GPU training. This all combines into a tool kit that can scale powerful algorithms to graph billions of connections.

## Article 3
### [Grain AI (Product Launch)](https://tldr.tech)
### Summary 
 Grain AI (Product Launch)

Grain is the easiest meeting insights tool to help you understand and communicate the needs of customers. Anybody in a customer-focused role can use Grain to record, transcribe, and clip moments from research interviews, sales calls, and customer meetings. They recently launched Grain AI, a tool that helps users unlock more value from their meetings with AI meeting summaries, quick meeting insights, and shareable customer insights.

## Article 4
### [Generate code by retrieving docs (31 minute read)](https://tldr.tech)
### Summary 
 Generate code by retrieving docs (31 minute read)

With code interfaces regularly changing and the limitation of in-context learning, there is a strong need to be able to update program synthesis performance without expensive data collection and model retraining. This work suggests that using documentation can improve the generated code of CodeT5. The results are good with ~3% improvement Pass@1. This isnE28099t a foundational change, but may be a useful trick for practitioners.

## Article 5
### [Language Is Not All You Need: Aligning Perception with Language Models (20 minute read)](https://tldr.tech)
### Summary 
 Language Is Not All You Need: Aligning Perception with Language Models (20 minute read)

KOSMOS-12 is a Multimodal Large Language Model that can learn in context, follow instructions, and perceive general modalities. It achieves impressive performance on a range of tasks, including language understanding, perception-language, and vision tasks. The model was trained on web-scale multimodal corpora and benefits from cross-modal transfer. The authors also introduce a dataset for diagnosing the nonverbal reasoning capability of MLLMs.

## Article 6
### [Directed Diffusion: Direct Control of Object Placement through Attention Guidance (12 minute read)](https://tldr.tech)
### Summary 
 Directed Diffusion: Direct Control of Object Placement through Attention Guidance (12 minute read)

Text-guided diffusion models struggle to compose scenes with multiple objects in specific positions, which is crucial in storytelling. To address this, the authors propose Directed Diffusion, a method that provides positional control over multiple objects by injecting "activation" at desired positions in cross-attention maps while attenuating the rest. This method can be used with an existing pre-trained model and requires only a few lines of implementation.

## Article 7
### [ChatLLaMA: ChatGPT based on MetaE28099s LLaMA models (GitHub Repo)](https://tldr.tech)
### Summary 
 ChatLLaMA: ChatGPT based on MetaE28099s LLaMA models (GitHub Repo)

Meta has recently released the LLaMA collection, consisting of 7 to 65 billion parameter models that are smaller than GPT-3 but show better performance. This new collection opens the door to faster inference performance and real-time assistants, while being cost-effective and running on a single GPU. However, they were not fine-tuned for instruction tasks. To address this, ChatLLaMA was introduced as the first open source implementation of LLaMA based on the Reinforcement Learning from Human Feedback (RLHF) training process. It supports all LLaMA model architectures, allowing for faster and cheaper training and inference compared to the original ChatGPT.

## Article 8
### [VoxFormer: a Cutting-edge Baseline for 3D Semantic Occupancy Prediction (Github Repo)](https://tldr.tech)
### Summary 
 VoxFormer: a Cutting-edge Baseline for 3D Semantic Occupancy Prediction (Github Repo)

The authors propose voxformer, a framework proposed to enable AI systems to imagine the complete 3D geometry of occluded objects and scenes from 2D images. VoxFormer uses a two-stage design where a sparse set of visible and occupied voxel queries from depth estimation is followed by a densification stage that generates dense 3D voxels. The framework adopts a masked autoencoder design to propagate the information to all the voxels by self-attention. Experiments on SemanticKITTI show that VoxFormer outperforms the state of the art with a relative improvement of 20.0% in geometry and 18.1% in semantics and reduces GPU memory during training by ~45% to less than 16GB.

## Article 9
### [40 Years of AI Compute (18 minute read)](https://tldr.tech)
### Summary 
 40 Years of AI Compute (18 minute read)

A nice compilation of various trends across the years in AI. Required computation doubles every 9 months while the number of parameters doubles every 18 months. Hardware improvements may improve through 2031. It doesnE28099t make sense to train models longer than 15 months. This is not exclusive to language but also includes vision and RL. Interactive charts included.

## Article 10
### [Calm down, there is no conscious AI (4 minute read)](https://tldr.tech)
### Summary 
 Calm down, there is no conscious AI (4 minute read)

This article reminds us that despite Bing AIE28099s and ChatGPTE28099s seemingly human responses, these chatbots are not conscious or sentient. We have a long way to go before we reach artificial general intelligence (AGI), which is what OpenAI originally set out to solve and protect humanity against.

## Article 11
### [Personalized AI content generation (Product Launch)](https://tldr.tech)
### Summary 
 Personalized AI content generation (Product Launch)

New company that combines multimodal model creation for useful enterprise uses.

## Article 12
### [Ask Seneca (Product Launch)</strong>](https://tldr.tech)
### Summary 
 Ask Seneca (Product Launch)</strong>

Get life advice from a GPT3-based stoic philosopher based on Seneca.

## Article 13
### [Meta Forming An AI Product Team (3 minute read)](https://tldr.tech)
### Summary 
 Meta Forming An AI Product Team (3 minute read)

Meta is forming an AI product team to focus on adding generative AI capabilities to WhatsApp, Messenger, and Instagram.

