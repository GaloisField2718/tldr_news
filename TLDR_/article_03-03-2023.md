# Articles TLDR  03-03-2023

## Article 1
### [Ford announces new self driving division E2809CLatitude AIE2809D (3 minute read)](https://tldr.tech)
### Summary 
 Ford announces new self driving division E2809CLatitude AIE2809D (3 minute read)

Ford is committed to the future of autonomous vehicles and this announcement confirms that. The 550 person Pittsburgh based team will continue working on technologies that have shipped in Ford products while also doing long term research towards fully autonomous vehicles. Long standing leaders in the field will lead the group in various capacities.

## Article 2
### [Google cloud CEO rallying cry about continued AI competency (2 minute read)](https://tldr.tech)
### Summary 
 Google cloud CEO rallying cry about continued AI competency (2 minute read)

With the AI race heating up, Google is feeling the pressure. In a recent internal meeting the Google Cloud CEO said E2809CThe game is never over in the first minuteE2809D and urged employees to work as a team to continue to improve AI capabilities. He talked about what the history books would say about Google navigating this time period and expressed optimism about the future of search.

## Article 3
### [Long convolutions and clever token mixing scales to be 100x faster at 64k tokens (60 minute read)](https://tldr.tech)
### Summary 
 Long convolutions and clever token mixing scales to be 100x faster at 64k tokens (60 minute read)

Another paper from the systems group at Stanford working on improving language modeling abilities for long context. They work to build a subquadratic attention replacement and build on much of their recent work in state space models and long convolutions work. They introduce the E2809CHyena HierarchyE2809D which is a drop in replacement for attention, while reducing FLOPs, and improving long context scaling. This is an exciting next step and worth a read.

## Article 4
### [Unlimited-Size Diffusion Restoration (9 minute read)](https://tldr.tech)
### Summary 
 Unlimited-Size Diffusion Restoration (9 minute read)

The paper discusses the use of diffusion models for zero-shot image restoration and proposes solutions for handling images of arbitrary sizes. The current methods only deal with fixed-size images, but the proposed approach uses Mask-Shift Restoration to address local incoherence and Hierarchical Restoration to alleviate out-of-domain issues. These parameter-free approaches can be used not only for image restoration but also for image generation of unlimited sizes, making them a potential general tool for diffusion models.

## Article 5
### [StraIT: Non-autoregressive Generation with Stratified Image Transformer (15 minute read)](https://tldr.tech)
### Summary 
 StraIT: Non-autoregressive Generation with Stratified Image Transformer (15 minute read)

The paper proposes a non-autoregressive (NAR) generative model called Stratified Image Transformer (StraIT) that outperforms existing autoregressive (AR) and diffusion models (DMs) in high-quality image synthesis. StraIT leverages the hierarchical nature of images to encode visual tokens into stratified levels, which alleviates modeling difficulty and lifts the generative power of NAR models. The experiments show that StraIT achieves FID scores of 3.96 at 256C397256 resolution on ImageNet without leveraging any guidance in sampling or auxiliary image classifiers.

## Article 6
### [Monocular Depth Estimation using Diffusion Models (Github Repo)](https://tldr.tech)
### Summary 
 Monocular Depth Estimation using Diffusion Models (Github Repo)

The authors propose a denoising diffusion model-based approach for monocular depth estimation. They introduce innovations to tackle noisy and incomplete depth maps, and leverage pre-training for supervised learning. Their DepthGen model achieves state-of-the-art performance and represents depth ambiguity naturally. The model's imputation support and zero-shot performance enable a simple text-to-3D pipeline.

## Article 7
### [Better control than ControlNet (HuggingFace Space)](https://tldr.tech)
### Summary 
 Better control than ControlNet (HuggingFace Space)

Another novel approach to controlling the geometric output of a text-to-image model. This time you can specify multiple regions to control. The general code is not yet available, but you can test the model out in this space.

## Article 8
### [Collage Diffusion: Precise Control over Collage-Conditional Image Generation (25 minute read)](https://tldr.tech)
### Summary 
 Collage Diffusion: Precise Control over Collage-Conditional Image Generation (25 minute read)

The paper proposes Collage Diffusion, a collage-conditional diffusion algorithm that enables precise control over the spatial arrangement and visual attributes of objects in generated images. By modifying the text-image cross-attention with alpha masks and learning specialized text representations per layer, users can edit individual components of generated images and control image harmonization on a layer-by-layer basis. Collage Diffusion generates globally harmonized images that maintain desired object locations and visual characteristics better than prior approaches.

## Article 9
### [EleutherAI retrospective (6 minute read)](https://tldr.tech)
### Summary 
 EleutherAI retrospective (6 minute read)

One of the top open science collaboratives in ML, Eleuther has made many contributions to the field over the past year and a half. They have published 28 papers, 10 different models, and dozens of code bases. Many of the most exciting developments such as RWKV, GPTNeo, and open replications of AlphaFold are coming from this group. Read more here about what theyE28099re working on and whatE28099s coming next.</span>

## Article 10
### [20B Flan UL2 Model released - fully open source with no restrictions (7 minute read)](https://tldr.tech)
### Summary 
 20B Flan UL2 Model released - fully open source with no restrictions (7 minute read)</span>

With a context length of 2048 tokens, this instruction tuned model is an excellent foundation model for text generation. With improved CoT, in context learning, and general performance (as much as 7.4% over FlanT5-xxl) this model is a great step forward in open source language models. This model uses the UL2 objective which is a mixture of denoisers and has shown impressive performance at general language modeling. Importantly, they also remove the need for cumbersome mode tokens by an additional 100k steps of training before the Flan instruction tuning process.

## Article 11
### [Inside the rise of OpenAI CTO Mira Murati (17 minute read)](https://tldr.tech)
### Summary 
 Inside the rise of OpenAI CTO Mira Murati (17 minute read)

This article is a deep dive into how OpenAI CTO Mira Murati became one of techE28099s most influential innovators.</span>

## Article 12
### [Romania unveils worldE28099s first AI government E2809CadvisorE2809D  (2 minute read)](https://tldr.tech)
### Summary 
 Romania unveils worldE28099s first AI government E2809CadvisorE2809D  (2 minute read)

The Romanian government has unveiled "Ion," an artificial intelligence (AI) based platform built to record Romanians' voices and opinions and use them to guide state policy decisions.

## Article 13
### [PromptCraft-Robotics (GitHub Repo)](https://tldr.tech)
### Summary 
 PromptCraft-Robotics (GitHub Repo)

PromptCrafts-Robotics is a community for people to test and share interesting prompting examples for LLMs within the robotics domain.

