# Articles TLDR  22-02-2023

## Article 1
### [Bain and OpenAI partnership (2 minute read)](https://tldr.tech)
### Summary 
 Bain and OpenAI partnership (2 minute read)

Custom model that can be used to answer business specific queries. It combines OpenAIE28099s industry-leading artificial intelligence tools and platforms and BainE28099s strategic guidance and digital implementation capabilities, helping companies harness the power of generative AI to transform their business.

## Article 2
### [AI and the Instagram Problem: Don't Let the Shiny Objects Make You Doubt the Worth of Your Work (5 minute read)](https://tldr.tech)
### Summary 
 AI and the Instagram Problem: Don't Let the Shiny Objects Make You Doubt the Worth of Your Work (5 minute read)

This article discusses how the prevalence of impressive AI projects on social media platforms like Instagram can make other developers feel inadequate about their own work. The author encourages AI developers to judge their projects based on their own standards and not to be swayed by what's currently trendy. The field of AI is constantly evolving, with new technologies emerging all the time, and it's important to keep learning and stay up to date. The article reminds developers that the emergence of a new hot technology doesn't mean their current project is any less valuable.

## Article 3
### [Talking about large language models (22 minute read)](https://tldr.tech)
### Summary 
 Talking about large language models (22 minute read)

Technology and Philosophy have found a fun intersection with Large Language Models (LLMs). We often use anthropomorphising words such as E2809CknowsE2809D, E2809CunderstandsE2809D, or E2809CbelievesE2809D when referring to these systems. This paper advocates the community to take care when talking about these extremely capable systems and use more fitting language (e.g., encodes, stores, contains).

## Article 4
### [Encoding images in text, unsupervised text-image alignment (32 minute read)](https://tldr.tech)
### Summary 
 Encoding images in text, unsupervised text-image alignment (32 minute read)

This paper introduces LQAE which uses a pre-trained language model and encodes images as a sequence of text tokens, then they train a decoder with the BERT masking objective which learns to represent similar images with similar clusters of text tokens. They train the decoder to reconstruct the original image from the predicted text token embeddings. This serves to align the two modalities in an unsupervised manner. A fun side effect is the ability to compress images as text (just a few kb) and reconstruct a lossy version via a single forward pass.

## Article 5
### [Pix2pix3D: 3D-aware Conditional Image Synthesis (5 minute read)](https://tldr.tech)
### Summary 
 Pix2pix3D: 3D-aware Conditional Image Synthesis (5 minute read)

This work proposes pix2pix3D, a 3D-aware conditional generative model for controllable photorealistic image synthesis. Given a 2D label map, such as a segmentation or edge map, the model learns to synthesize a corresponding image from different viewpoints. To enable explicit 3D user control, the authors extend conditional generative models with neural radiance fields. Given widely-available monocular images and label map pairs, the model learns to assign a label to every 3D point in addition to color and density, which enables it to render the image and pixel-aligned label map simultaneously.

## Article 6
### [Turn your DataFrame into a UI for visual analysis (GitHub Repo)](https://tldr.tech)
### Summary 
 Turn your DataFrame into a UI for visual analysis (GitHub Repo)

PyGWalker (pronounced Pig Walker) is a graphical tool for exploratory analysis of your data. It allows you to quickly inspect relationships, correlations, and distributions. Examples and screenshots are available in the repository readme.

## Article 7
### [Universal audio synthesis model (GitHub Repo)](https://tldr.tech)
### Summary 
 Universal audio synthesis model (GitHub Repo)

Universal vocoder for generating high fidelity audio with the ability to condition on specific features. This is the first large scale GAN model of its kind. Models, code, and samples are available.

## Article 8
### [ControlNet: A neural network structure to control diffusion models by adding extra conditions (GitHub Repo)](https://tldr.tech)
### Summary 
 ControlNet: A neural network structure to control diffusion models by adding extra conditions (GitHub Repo)

Researchers have introduced a neural network structure called ControlNet, which can control pretrained large diffusion models to support additional input conditions. This new method allows for task-specific learning in an end-to-end fashion and is capable of learning with a small training dataset. The training is as fast as fine-tuning a diffusion model and can be done on a personal device, or it can scale to large amounts of data using powerful computation clusters. The researchers demonstrate that ControlNets can enable conditional inputs such as edge maps, segmentation maps, and key points for large diffusion models, which can benefit various related applications.

## Article 9
### [BioGPT (GitHub Repo)](https://tldr.tech)
### Summary 
 BioGPT (GitHub Repo)

This GitHub repository contains the implementation of BioGPT, a generative pre-trained transformer for biomedical text generation and mining. It outperforms GPT-3 with just a fraction of the parameters.

## Article 10
### [Fast Attention lecture from Stanford MLSys group (58 minute video)](https://tldr.tech)
### Summary 
 Fast Attention lecture from Stanford MLSys group (58 minute video)

A great lecture on one of the primary systems breakthroughs in recent times for Transformers. Flash Attention has been adopted by almost all the major deep learning frameworks and leads to dramatic speed ups and improved context length.

## Article 11
### [University of WaterlooE28099s E2809COptimization for data scienceE2809D course became available (Online Course)](https://tldr.tech)
### Summary 
 University of WaterlooE28099s E2809COptimization for data scienceE2809D course became available (Online Course)

This course, "Optimization for data science," covers the fundamental principles and techniques of optimization as they apply to data science.

## Article 12
### [To understand language models, we must separate E2809ClanguageE2809D from E2809CthoughtE2809D (9 minute read)](https://tldr.tech)
### Summary 
 To understand language models, we must separate E2809ClanguageE2809D from E2809CthoughtE2809D (9 minute read)

The researchers from the University of Texas at Austin and MIT have written a paper that delves into the confusion surrounding Large Language Models (LLMs). They argue that to understand the power and limits of LLMs, we must distinguish between formal and functional linguistic competence. They highlight the fallacies surrounding LLMs and state that LLMs are good at language but still have a lot of work to do on the functional aspect of language. They suggest that avoiding these fallacies could help in finding ways to build models that understand and use language in human-like ways.

## Article 13
### [Magazine Pauses Submissions Due To Surge Of AI-Generated Content (1 minute read)](https://tldr.tech)
### Summary 
 Magazine Pauses Submissions Due To Surge Of AI-Generated Content (1 minute read)

Sci-Fi publication Clarkesworld Magazine is pausing short story submissions, citing an influx in AI-generated content.

